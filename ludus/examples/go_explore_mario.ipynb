{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "from ludus.policies import BaseTrainer\n",
    "from ludus.env import EnvController\n",
    "from ludus.utils import preprocess_atari, reshape_train_var\n",
    "from ludus.memory import MemoryBuffer\n",
    "import gym\n",
    "import cv2\n",
    "import copy\n",
    "import threading\n",
    "import time\n",
    "# Super Mario stuff\n",
    "from nes_py.wrappers import BinarySpaceToDiscreteSpaceEnv\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "    env = BinarySpaceToDiscreteSpaceEnv(env, SIMPLE_MOVEMENT)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellMemory():\n",
    "    def __init__(self, state_filter):\n",
    "        self.n_cells = 0\n",
    "        self.cells = {}\n",
    "        self.filter = state_filter\n",
    "    \n",
    "    def new_cell(self, state, act_seq=[], total_reward=0, total_steps=0, **attribs):\n",
    "        new_cell = {'state': state, \n",
    "                    'act_seq': act_seq, \n",
    "                    'total_reward': total_reward,\n",
    "                    'total_steps': total_steps,\n",
    "                    'access': 1}\n",
    "        \n",
    "        for a in attribs:\n",
    "            new_cell[a] = attribs[a]\n",
    "            \n",
    "        return new_cell\n",
    "        \n",
    "    \n",
    "    def add_cell(self, state, act_seq=[], total_reward=0, total_steps=0, **attribs):\n",
    "        nstate = self.filter(state)\n",
    "        state_key = nstate.data.tobytes()\n",
    "        if state_key in self.cells:\n",
    "            cell = self.cells[state_key]\n",
    "            if total_reward > cell['total_reward']:\n",
    "                self.cells[state_key] = self.new_cell(nstate, act_seq, total_reward, total_steps, **attribs)\n",
    "            elif total_reward == cell['total_reward'] and total_steps < cell['total_steps']:\n",
    "                self.cells[state_key] = self.new_cell(nstate, act_seq, total_reward, total_steps, **attribs)\n",
    "        else:\n",
    "            self.cells[state_key] = self.new_cell(nstate, act_seq, total_reward, total_steps, **attribs)\n",
    "            self.n_cells += 1\n",
    "        \n",
    "    def get_cell(self, state):\n",
    "        nstate = self.filter(state)\n",
    "        state_key = nstate.data.tobytes()\n",
    "        if state_key in self.cells:\n",
    "            self.cells[state_key]['access'] += 1\n",
    "            return self.cells[state_key]\n",
    "    \n",
    "    def get_random_cell(self):\n",
    "        if self.n_cells == 0:\n",
    "            return None\n",
    "        state_key = np.random.choice(list(self.cells.keys()))\n",
    "        self.cells[state_key]['access'] += 1\n",
    "        return self.cells[state_key]\n",
    "    \n",
    "    def heuristic_choose(self):\n",
    "        rewards = []\n",
    "        steps = []\n",
    "        rew_step_ratio = []\n",
    "        access = []\n",
    "        choice_keys = []\n",
    "        \n",
    "        for key, cell in self.cells.items():\n",
    "            rewards.append(cell['total_reward'])\n",
    "            steps.append(cell['total_steps']+1)\n",
    "            rew_step_ratio.append(cell['total_reward'] / (cell['total_steps']+1))\n",
    "            access.append(cell['access'])\n",
    "            choice_keys.append(key)\n",
    "            \n",
    "        max_reward = max(1, max(rewards))\n",
    "        max_steps = max(steps)\n",
    "        max_rew_step_ratio = max(1, max(rew_step_ratio))\n",
    "        max_access = max(access)\n",
    "        heuristics = np.zeros((len(choice_keys),))\n",
    "        for i in range(len(choice_keys)):\n",
    "            rewards[i] /= max_reward\n",
    "            steps[i] = (max_steps - steps[i]) / max_steps\n",
    "            rew_step_ratio[i] /= max_rew_step_ratio\n",
    "            access[i] = (max_access - access[i]) / max_access\n",
    "            heuristics[i] = 10*rewards[i] + steps[i] + 2*rew_step_ratio[i] + access[i]\n",
    "            \n",
    "        s = sum(heuristics)\n",
    "        heuristics /= s\n",
    "        key = np.random.choice(choice_keys, p=heuristics)\n",
    "        return self.cells[key]\n",
    "    \n",
    "    def get_best_cell(self):\n",
    "        if self.n_cells == 0:\n",
    "            return None\n",
    "        \n",
    "        best_cell = None\n",
    "        max_rew = -1e9\n",
    "        for _, cell in self.cells.items():\n",
    "            if cell['total_reward'] > max_rew:\n",
    "                max_rew = cell['total_reward']\n",
    "                best_cell = cell\n",
    "                \n",
    "        return best_cell\n",
    "    \n",
    "    def clear(self):\n",
    "        self.sells = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_filter(obs, shape=(8, 12)):\n",
    "    \"\"\"Applies grayscale, resize, and scale_color to one observation, returning the new img\"\"\"\n",
    "    gray = np.dot(obs[:,:,:3], [0.299, 0.587, 0.114])\n",
    "    resized = cv2.resize(gray, dsize=shape, interpolation=cv2.INTER_LANCZOS4).reshape(shape)\n",
    "    return resized / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = CellMemory(state_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_func(lock, stop_signal, wait_signal):\n",
    "    env = make_env()\n",
    "    obs = env.reset()\n",
    "    archive.add_cell(obs)\n",
    "    for episode in range(n_episodes):\n",
    "        if stop_signal.is_set():\n",
    "            break\n",
    "            \n",
    "        while wait_signal.is_set():\n",
    "            time.sleep(0.01)\n",
    "        \n",
    "        with lock:\n",
    "            cell = archive.heuristic_choose()\n",
    "\n",
    "        obs = env.reset()\n",
    "        early_terminate = False\n",
    "        all_acts = []\n",
    "        for act in cell['act_seq']:\n",
    "            obs, _, d, _ = env.step(act)\n",
    "            all_acts.append(act)\n",
    "            \n",
    "            if d:\n",
    "                early_terminate = True\n",
    "                break\n",
    "        \n",
    "        if state_filter(obs).data != cell['state'].data:\n",
    "            print('stochastic')\n",
    "            print(state_filter(obs) - cell['state'].data)\n",
    "        \n",
    "        if early_terminate:\n",
    "            break\n",
    "            \n",
    "        total_reward = cell['total_reward']\n",
    "        for step in range(exp_steps):\n",
    "            new_act = env.action_space.sample()\n",
    "            obs, r, d, _ = env.step(new_act)\n",
    "\n",
    "            if d:\n",
    "                break\n",
    "\n",
    "            all_acts.append(new_act)\n",
    "            total_reward += r\n",
    "            with lock:\n",
    "                if total_reward >= cell['total_reward'] + 5 and np.random.randint(0, 6) == 0:\n",
    "                        archive.add_cell(obs, act_seq=all_acts[:], total_reward=total_reward, \\\n",
    "                                         total_steps=len(all_acts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 50000\n",
    "exp_steps = 100\n",
    "n_threads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n",
      "/home/ejmejm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Count: 2700, Highest Reward: 798\n",
      "Cell Count: 4641, Highest Reward: 798\n",
      "Cell Count: 6603, Highest Reward: 905\n",
      "Cell Count: 8064, Highest Reward: 905\n",
      "Cell Count: 9555, Highest Reward: 953\n",
      "Cell Count: 10742, Highest Reward: 1030\n",
      "Cell Count: 12194, Highest Reward: 1082\n",
      "Cell Count: 13613, Highest Reward: 1117\n",
      "Cell Count: 14782, Highest Reward: 1117\n",
      "Cell Count: 16027, Highest Reward: 1117\n",
      "Cell Count: 17228, Highest Reward: 1117\n",
      "Cell Count: 18468, Highest Reward: 1117\n",
      "Cell Count: 19669, Highest Reward: 1254\n",
      "Cell Count: 20899, Highest Reward: 1254\n",
      "Cell Count: 22043, Highest Reward: 1254\n",
      "Cell Count: 23183, Highest Reward: 1254\n",
      "Cell Count: 24134, Highest Reward: 1271\n",
      "Cell Count: 25223, Highest Reward: 1413\n",
      "Cell Count: 26397, Highest Reward: 1413\n",
      "Cell Count: 27399, Highest Reward: 1413\n",
      "Cell Count: 28386, Highest Reward: 1413\n",
      "Cell Count: 29494, Highest Reward: 1413\n",
      "Cell Count: 30431, Highest Reward: 1413\n",
      "Cell Count: 31426, Highest Reward: 1413\n",
      "Cell Count: 32329, Highest Reward: 1413\n",
      "Cell Count: 33106, Highest Reward: 1413\n",
      "Cell Count: 34054, Highest Reward: 1413\n",
      "Cell Count: 34876, Highest Reward: 1413\n",
      "Cell Count: 35710, Highest Reward: 1413\n",
      "Cell Count: 36616, Highest Reward: 1413\n",
      "Cell Count: 37392, Highest Reward: 1413\n",
      "Cell Count: 38143, Highest Reward: 1416\n",
      "Cell Count: 38932, Highest Reward: 1416\n",
      "Cell Count: 39800, Highest Reward: 1416\n",
      "Cell Count: 40643, Highest Reward: 1416\n",
      "Cell Count: 41421, Highest Reward: 1416\n",
      "Cell Count: 42220, Highest Reward: 1416\n",
      "Cell Count: 43065, Highest Reward: 1423\n",
      "Cell Count: 43767, Highest Reward: 1423\n",
      "Cell Count: 44535, Highest Reward: 1423\n",
      "Cell Count: 45359, Highest Reward: 1423\n",
      "Cell Count: 46305, Highest Reward: 1423\n",
      "Cell Count: 47075, Highest Reward: 1423\n",
      "Cell Count: 47856, Highest Reward: 1423\n",
      "Cell Count: 48586, Highest Reward: 1423\n",
      "Cell Count: 49449, Highest Reward: 1423\n",
      "Cell Count: 50144, Highest Reward: 1423\n",
      "Cell Count: 50848, Highest Reward: 1423\n",
      "Cell Count: 51523, Highest Reward: 1423\n",
      "Cell Count: 52303, Highest Reward: 1423\n",
      "Cell Count: 52929, Highest Reward: 1423\n",
      "Cell Count: 53564, Highest Reward: 1423\n",
      "Cell Count: 54224, Highest Reward: 1423\n",
      "Cell Count: 54914, Highest Reward: 1423\n",
      "Cell Count: 55550, Highest Reward: 1468\n",
      "Cell Count: 56226, Highest Reward: 1468\n",
      "Cell Count: 56888, Highest Reward: 1489\n",
      "Cell Count: 57478, Highest Reward: 1489\n",
      "Cell Count: 58252, Highest Reward: 1489\n",
      "Cell Count: 58976, Highest Reward: 1489\n",
      "Cell Count: 59807, Highest Reward: 1489\n",
      "Cell Count: 60494, Highest Reward: 1489\n",
      "Cell Count: 61197, Highest Reward: 1489\n",
      "Cell Count: 61842, Highest Reward: 1489\n",
      "Cell Count: 62504, Highest Reward: 1489\n",
      "Cell Count: 63219, Highest Reward: 1489\n",
      "Cell Count: 63811, Highest Reward: 1489\n",
      "Cell Count: 64455, Highest Reward: 1489\n",
      "Cell Count: 65183, Highest Reward: 1530\n",
      "Cell Count: 65789, Highest Reward: 1530\n",
      "Cell Count: 66597, Highest Reward: 1530\n",
      "Cell Count: 67190, Highest Reward: 1530\n",
      "Cell Count: 67781, Highest Reward: 1530\n",
      "Cell Count: 68397, Highest Reward: 1530\n",
      "Cell Count: 69107, Highest Reward: 1530\n",
      "Cell Count: 69741, Highest Reward: 1530\n",
      "Cell Count: 70346, Highest Reward: 1530\n",
      "Cell Count: 71016, Highest Reward: 1530\n",
      "Cell Count: 71694, Highest Reward: 1540\n",
      "Cell Count: 72387, Highest Reward: 1540\n",
      "Cell Count: 73057, Highest Reward: 1540\n",
      "Cell Count: 73661, Highest Reward: 1540\n",
      "Cell Count: 74248, Highest Reward: 1540\n",
      "Cell Count: 74760, Highest Reward: 1540\n",
      "Cell Count: 75396, Highest Reward: 1540\n",
      "Cell Count: 76146, Highest Reward: 1571\n",
      "Cell Count: 76721, Highest Reward: 1571\n",
      "Cell Count: 77422, Highest Reward: 1571\n",
      "Cell Count: 77948, Highest Reward: 1571\n",
      "Cell Count: 78567, Highest Reward: 1571\n",
      "Cell Count: 79129, Highest Reward: 1571\n",
      "Cell Count: 79744, Highest Reward: 1571\n",
      "Cell Count: 80203, Highest Reward: 1571\n",
      "Cell Count: 80806, Highest Reward: 1571\n",
      "Cell Count: 81371, Highest Reward: 1571\n",
      "Cell Count: 81969, Highest Reward: 1571\n",
      "Cell Count: 82543, Highest Reward: 1571\n",
      "Cell Count: 83128, Highest Reward: 1571\n",
      "Cell Count: 83755, Highest Reward: 1571\n",
      "Cell Count: 84271, Highest Reward: 1571\n",
      "Cell Count: 84919, Highest Reward: 1571\n",
      "Cell Count: 85477, Highest Reward: 1571\n",
      "Cell Count: 86024, Highest Reward: 1571\n",
      "Cell Count: 86582, Highest Reward: 1571\n",
      "Cell Count: 87171, Highest Reward: 1571\n",
      "Cell Count: 87755, Highest Reward: 1571\n",
      "Cell Count: 88332, Highest Reward: 1631\n",
      "Cell Count: 88892, Highest Reward: 1631\n",
      "Cell Count: 89532, Highest Reward: 1631\n",
      "Cell Count: 90046, Highest Reward: 1631\n",
      "Cell Count: 90499, Highest Reward: 1631\n",
      "Cell Count: 90977, Highest Reward: 1631\n",
      "Cell Count: 91526, Highest Reward: 1631\n",
      "Cell Count: 92027, Highest Reward: 1631\n",
      "Cell Count: 92357, Highest Reward: 1631\n",
      "Cell Count: 92829, Highest Reward: 1631\n",
      "Cell Count: 93188, Highest Reward: 1631\n",
      "Cell Count: 93500, Highest Reward: 1631\n",
      "Cell Count: 93995, Highest Reward: 1631\n",
      "Cell Count: 94406, Highest Reward: 1631\n",
      "Cell Count: 94713, Highest Reward: 1631\n",
      "Cell Count: 95154, Highest Reward: 1631\n",
      "Cell Count: 95546, Highest Reward: 1631\n",
      "Cell Count: 96170, Highest Reward: 1631\n",
      "Cell Count: 96604, Highest Reward: 1631\n",
      "Cell Count: 97070, Highest Reward: 1631\n",
      "Cell Count: 97435, Highest Reward: 1780\n",
      "Cell Count: 97742, Highest Reward: 1780\n",
      "Cell Count: 98161, Highest Reward: 1780\n",
      "Cell Count: 98538, Highest Reward: 1780\n",
      "Cell Count: 98944, Highest Reward: 1780\n",
      "Cell Count: 99267, Highest Reward: 1780\n",
      "Cell Count: 99683, Highest Reward: 1780\n",
      "Cell Count: 100072, Highest Reward: 1780\n",
      "Cell Count: 100532, Highest Reward: 1780\n",
      "Cell Count: 100952, Highest Reward: 1780\n",
      "Cell Count: 101429, Highest Reward: 1780\n",
      "Cell Count: 101832, Highest Reward: 1780\n",
      "Cell Count: 102213, Highest Reward: 1780\n",
      "Cell Count: 102614, Highest Reward: 1780\n",
      "Cell Count: 102995, Highest Reward: 1780\n",
      "Cell Count: 103415, Highest Reward: 1780\n",
      "Cell Count: 103792, Highest Reward: 1780\n",
      "Cell Count: 104127, Highest Reward: 1780\n",
      "Cell Count: 104581, Highest Reward: 1780\n",
      "Cell Count: 105022, Highest Reward: 1780\n",
      "Cell Count: 105410, Highest Reward: 1780\n",
      "Cell Count: 105834, Highest Reward: 1780\n",
      "Cell Count: 106215, Highest Reward: 1780\n",
      "Cell Count: 106649, Highest Reward: 1780\n",
      "Cell Count: 107044, Highest Reward: 1780\n",
      "Cell Count: 107363, Highest Reward: 1780\n",
      "Cell Count: 107788, Highest Reward: 1780\n",
      "Cell Count: 108221, Highest Reward: 1780\n",
      "Cell Count: 108636, Highest Reward: 1780\n",
      "Cell Count: 109049, Highest Reward: 1780\n",
      "Cell Count: 109418, Highest Reward: 1780\n",
      "Cell Count: 109803, Highest Reward: 1780\n",
      "Cell Count: 110194, Highest Reward: 1780\n",
      "Cell Count: 110653, Highest Reward: 1780\n",
      "Cell Count: 110992, Highest Reward: 1780\n",
      "Cell Count: 111288, Highest Reward: 1780\n",
      "Cell Count: 111679, Highest Reward: 1780\n",
      "Cell Count: 111949, Highest Reward: 1780\n",
      "Cell Count: 112332, Highest Reward: 1780\n",
      "Cell Count: 112717, Highest Reward: 1780\n",
      "Cell Count: 113116, Highest Reward: 1780\n",
      "Cell Count: 113505, Highest Reward: 1780\n",
      "Cell Count: 113839, Highest Reward: 1780\n",
      "Cell Count: 114314, Highest Reward: 1780\n",
      "Cell Count: 114660, Highest Reward: 1780\n",
      "Cell Count: 115056, Highest Reward: 1780\n",
      "Cell Count: 115423, Highest Reward: 1780\n",
      "Cell Count: 115863, Highest Reward: 1780\n",
      "Cell Count: 116186, Highest Reward: 1780\n",
      "Cell Count: 116580, Highest Reward: 1780\n",
      "Cell Count: 116926, Highest Reward: 1780\n",
      "Cell Count: 117238, Highest Reward: 1780\n",
      "Cell Count: 117667, Highest Reward: 1780\n",
      "Cell Count: 117997, Highest Reward: 1780\n",
      "Cell Count: 118346, Highest Reward: 1780\n",
      "Cell Count: 118783, Highest Reward: 1780\n",
      "Cell Count: 119131, Highest Reward: 1780\n",
      "Cell Count: 119495, Highest Reward: 1780\n",
      "Cell Count: 119928, Highest Reward: 1780\n",
      "Cell Count: 120274, Highest Reward: 1780\n",
      "Cell Count: 120661, Highest Reward: 1780\n",
      "Cell Count: 121103, Highest Reward: 1780\n",
      "Cell Count: 121466, Highest Reward: 1780\n",
      "Cell Count: 121886, Highest Reward: 1780\n",
      "Cell Count: 122202, Highest Reward: 1780\n",
      "Cell Count: 122630, Highest Reward: 1780\n",
      "Cell Count: 122916, Highest Reward: 1780\n",
      "Cell Count: 123263, Highest Reward: 1780\n",
      "Cell Count: 123705, Highest Reward: 1780\n",
      "Cell Count: 124100, Highest Reward: 1780\n",
      "Cell Count: 124406, Highest Reward: 1780\n",
      "Cell Count: 124842, Highest Reward: 1780\n",
      "Cell Count: 125126, Highest Reward: 1783\n",
      "Cell Count: 125469, Highest Reward: 1783\n",
      "Cell Count: 125835, Highest Reward: 1783\n",
      "Cell Count: 126212, Highest Reward: 1783\n",
      "Cell Count: 126542, Highest Reward: 1783\n",
      "Cell Count: 126898, Highest Reward: 1783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Count: 127261, Highest Reward: 1783\n",
      "Cell Count: 127513, Highest Reward: 1783\n",
      "Cell Count: 127840, Highest Reward: 1783\n",
      "Cell Count: 128164, Highest Reward: 1783\n",
      "Cell Count: 128456, Highest Reward: 1783\n",
      "Cell Count: 128814, Highest Reward: 1783\n",
      "Cell Count: 129209, Highest Reward: 1783\n",
      "Cell Count: 129597, Highest Reward: 1783\n",
      "Cell Count: 129897, Highest Reward: 1783\n",
      "Cell Count: 130296, Highest Reward: 1783\n",
      "Cell Count: 130631, Highest Reward: 1783\n",
      "Cell Count: 130915, Highest Reward: 1783\n",
      "Cell Count: 131256, Highest Reward: 1783\n",
      "Cell Count: 131666, Highest Reward: 1783\n",
      "Cell Count: 131935, Highest Reward: 1783\n",
      "Cell Count: 132277, Highest Reward: 1783\n",
      "Cell Count: 132714, Highest Reward: 1783\n",
      "Cell Count: 133060, Highest Reward: 1783\n",
      "Cell Count: 133304, Highest Reward: 1783\n",
      "Cell Count: 133714, Highest Reward: 1783\n",
      "Cell Count: 134056, Highest Reward: 1783\n",
      "Cell Count: 134413, Highest Reward: 1783\n",
      "Cell Count: 134809, Highest Reward: 1783\n",
      "Cell Count: 135089, Highest Reward: 1783\n",
      "Cell Count: 135515, Highest Reward: 1783\n",
      "Cell Count: 135787, Highest Reward: 1783\n",
      "Cell Count: 136132, Highest Reward: 1783\n",
      "Cell Count: 136490, Highest Reward: 1783\n",
      "Cell Count: 136833, Highest Reward: 1783\n",
      "Cell Count: 137156, Highest Reward: 1783\n",
      "Cell Count: 137505, Highest Reward: 1783\n",
      "Cell Count: 137846, Highest Reward: 1783\n",
      "Cell Count: 138200, Highest Reward: 1783\n",
      "Cell Count: 138617, Highest Reward: 1783\n",
      "Cell Count: 138975, Highest Reward: 1783\n",
      "Cell Count: 139346, Highest Reward: 1783\n",
      "Cell Count: 139692, Highest Reward: 1783\n",
      "Cell Count: 140116, Highest Reward: 1783\n",
      "Cell Count: 140462, Highest Reward: 1783\n",
      "Cell Count: 140795, Highest Reward: 1783\n",
      "Cell Count: 141134, Highest Reward: 1783\n",
      "Cell Count: 141483, Highest Reward: 1783\n",
      "Cell Count: 141836, Highest Reward: 1783\n",
      "Cell Count: 142170, Highest Reward: 1783\n",
      "Cell Count: 142581, Highest Reward: 1783\n",
      "Cell Count: 142946, Highest Reward: 1783\n",
      "Cell Count: 143243, Highest Reward: 1783\n",
      "Cell Count: 143568, Highest Reward: 1783\n",
      "Cell Count: 143959, Highest Reward: 1783\n",
      "Cell Count: 144337, Highest Reward: 1783\n",
      "Cell Count: 144707, Highest Reward: 1783\n",
      "Cell Count: 145069, Highest Reward: 1783\n",
      "Cell Count: 145430, Highest Reward: 1783\n",
      "Cell Count: 145757, Highest Reward: 1783\n",
      "Cell Count: 146086, Highest Reward: 1783\n",
      "Cell Count: 146393, Highest Reward: 1783\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6bad2c32414a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lock = threading.Lock()\n",
    "stop_signal = threading.Event()\n",
    "wait_signal = threading.Event()\n",
    "\n",
    "threads = []\n",
    "for i in range(n_threads):\n",
    "    threads.append(threading.Thread(target=worker_func, args=(lock, stop_signal, wait_signal,)))\n",
    "    threads[-1].start()\n",
    "    \n",
    "while len(threads) > 0:\n",
    "    time.sleep(60)\n",
    "    \n",
    "    with lock:\n",
    "        best_cell = archive.get_best_cell()\n",
    "\n",
    "    print('Cell Count: {}, Highest Reward: {}'.format(archive.n_cells, best_cell['total_reward']))\n",
    "    \n",
    "    threads = [t for t in threads if t.isAlive()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_signal.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "cell = archive.get_best_cell()\n",
    "\n",
    "env = make_env()\n",
    "obs = env.reset()\n",
    "for act in cell['act_seq']:\n",
    "    obs, _, d, _ = env.step(act)\n",
    "    env.render()\n",
    "    time.sleep(0.02)\n",
    "    if d:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### archive.get_best_cell()['total_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = make_env()\n",
    "# obs = env.reset()\n",
    "# archive.add_cell(obs)\n",
    "\n",
    "# for episode in range(n_episodes):\n",
    "#     cell = archive.get_random_cell()\n",
    "    \n",
    "#     all_acts = []\n",
    "#     for act in cell['act_seq']:\n",
    "#         env.step(act)\n",
    "#         all_acts.append(act)\n",
    "    \n",
    "#     total_reward = cell['total_reward']\n",
    "#     for step in range(exp_steps):\n",
    "#         new_act = env.action_space.sample()\n",
    "#         obs, r, d, _ = env.step(new_act)\n",
    "        \n",
    "#         if d:\n",
    "#             break\n",
    "        \n",
    "#         all_acts.append(new_act)\n",
    "#         total_reward += r\n",
    "#         if total_reward >= cell['total_reward']:\n",
    "#             archive.add_cell(obs, act_seq=all_acts[:], total_reward=total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
