{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "from ludus.policies import BaseTrainer\n",
    "from ludus.env import EnvController\n",
    "from ludus.utils import preprocess_atari, reshape_train_var\n",
    "from ludus.memory import MTMemoryBuffer\n",
    "import gym\n",
    "# Super Mario stuff\n",
    "from nes_py.wrappers import BinarySpaceToDiscreteSpaceEnv\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    env = gym_super_mario_bros.make('Breakout-v0')\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMTrainer(BaseTrainer):\n",
    "    def __init__(self, in_op, out_op, value_out_op, act_type='discrete', sess=None, clip_val=0.2, ppo_iters=80,\n",
    "                 target_kl=0.01, v_coef=1., entropy_coef=0.01):\n",
    "        self.value_out_op = value_out_op\n",
    "        self.clip_val = clip_val\n",
    "        self.ppo_iters = ppo_iters\n",
    "        self.target_kl = target_kl\n",
    "        self.v_coef = v_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        \n",
    "        # ICM parameters, TODO: make parameters for these\n",
    "        self.ro_coef = 0.5\n",
    "        self.beta = 0.2\n",
    "        self.eta = 1\n",
    "        self.r_i_coef = 1\n",
    "        self.r_e_coef = 0.2\n",
    "        \n",
    "        super().__init__(in_op, out_op, act_type, sess)\n",
    "        \n",
    "    def _create_ICM(self, optimizer=tf.train.AdamOptimizer()):\n",
    "        feature_dim = 64 # TODO: make a parameter for this\n",
    "        \n",
    "        # Create placeholder\n",
    "        self.next_obs_holders = tf.placeholder(tf.float32, shape=self.in_op.shape)\n",
    "        \n",
    "        # Observation feature encoder\n",
    "        with tf.variable_scope('feature_encoder'):\n",
    "            enc_layers = [\n",
    "                Conv2D(16, 4, activation=tf.nn.tanh, name='fe_conv'),\n",
    "                MaxPool2D(2, name='fe_max_pool'),\n",
    "                Conv2D(32, 3, activation=tf.nn.tanh, name='fe_conv2'),\n",
    "                MaxPool2D(2, name='fe_max_pool2'),\n",
    "                Conv2D(32, 3, activation=tf.nn.tanh, name='fe_conv3'),\n",
    "                MaxPool2D(2, name='fe_max_pool3'),\n",
    "                Flatten(name='fe_flattened'),\n",
    "                Dense(feature_dim, activation=tf.nn.tanh, use_bias=False, name='fe_dense')\n",
    "            ]\n",
    "            \n",
    "            # Encoding state\n",
    "            self.f_obs = enc_layers[0](self.in_op)\n",
    "            for i in range(1, len(enc_layers)):\n",
    "                self.f_obs = enc_layers[i](self.f_obs)\n",
    "            \n",
    "            # Encoding the next state\n",
    "            self.f_obs_next = enc_layers[0](self.next_obs_holders)\n",
    "            for i in range(1, len(enc_layers)):\n",
    "                self.f_obs_next = enc_layers[i](self.f_obs_next)\n",
    "            \n",
    "        # State predictor forward model\n",
    "        with tf.variable_scope('forward_model'):\n",
    "            self.state_act_pair = tf.concat([self.out_op, self.f_obs], axis=1)\n",
    "            self.sp_dense = Dense(64, activation=tf.nn.tanh)(self.state_act_pair)\n",
    "            self.f_obs_next_pred = Dense(feature_dim, activation=tf.nn.tanh, use_bias=False)(self.sp_dense)\n",
    "        \n",
    "        # Inverse dynamics model (predicting action)\n",
    "        with tf.variable_scope('inverse_model'):\n",
    "            self.state_state_pair = tf.concat([self.f_obs, self.f_obs_next], axis=1)\n",
    "            self.act_preds = Dense(64, activation=tf.nn.relu)(self.state_state_pair)\n",
    "            # TODO: softmax only works for discrete, make continuous version\n",
    "            self.act_preds = Dense(self.out_op.shape[1].value, use_bias=False, activation=tf.nn.softmax)(self.act_preds)\n",
    "        \n",
    "        # Calculating intrinsic reward\n",
    "        self.obs_pred_diff = self.f_obs_next_pred - self.f_obs_next\n",
    "        self.r_i = 0.5 * self.eta * tf.reduce_sum(self.obs_pred_diff ** 2, axis=1) # Fix these squares (Probably okay)\n",
    "        self.r_ie = self.r_i_coef * self.r_i # + self.r_e_coef * self.reward_holders\n",
    "        \n",
    "        # Calculating losses\n",
    "        self.pre_loss_i = categorical_crossentropy(self.act_masks, self.act_preds) # tf.reduce_sum((self.act_holders - self.act_pred) ** 2, axis=1)\n",
    "        self.pre_loss_f = 0.5 * tf.reduce_sum(self.obs_pred_diff ** 2, axis=1)\n",
    "        \n",
    "        self.loss_i = (1 - self.beta) * tf.reduce_mean(self.pre_loss_i)\n",
    "        self.loss_f = self.beta * tf.reduce_mean(self.pre_loss_f)\n",
    "        self.loss_p = -self.ro_coef * tf.reduce_mean(self.r_ie)\n",
    "        \n",
    "        # Making update functions\n",
    "        self.i_train_vars = tf.trainable_variables(scope='feature_encoder') + tf.trainable_variables(scope='inverse_model')\n",
    "        self.f_train_vars = tf.trainable_variables(scope='forward_model')\n",
    "        self.p_train_vars = [var for var in tf.trainable_variables() if var not in (self.i_train_vars + self.f_train_vars)]\n",
    "        \n",
    "        self.li_update = optimizer.minimize(self.loss_i, var_list=self.i_train_vars)\n",
    "        self.lf_update = optimizer.minimize(self.loss_f, var_list=self.f_train_vars)\n",
    "        self.lp_update = optimizer.minimize(self.loss_p, var_list=self.f_train_vars)\n",
    "        \n",
    "        self.icm_updates = [self.li_update, self.lf_update, self.lp_update]\n",
    "        self.losses = [self.loss_i, self.loss_f, self.loss_p]\n",
    "        \n",
    "    def _create_discrete_trainer(self, optimizer=tf.train.AdamOptimizer()):\n",
    "        \"\"\"\n",
    "        Creates a function for vanilla policy training with a discrete action space\n",
    "        \"\"\"\n",
    "        # First passthrough\n",
    "        \n",
    "        self.act_holders = tf.placeholder(tf.int32, shape=[None])\n",
    "        self.reward_holders = tf.placeholder(tf.float32, shape=[None])\n",
    "        \n",
    "        self.act_masks = tf.one_hot(self.act_holders, self.out_op.shape[1].value, dtype=tf.float32)\n",
    "        self.resp_acts = tf.reduce_sum(self.act_masks *  self.out_op, axis=1)\n",
    "        \n",
    "        self.advantages = self.reward_holders - tf.squeeze(self.value_out_op)\n",
    "        \n",
    "        self._create_ICM()\n",
    "        \n",
    "        # Second passthrough\n",
    "        \n",
    "        self.advatange_holders = tf.placeholder(dtype=tf.float32, shape=self.advantages.shape)\n",
    "        self.old_prob_holders = tf.placeholder(dtype=tf.float32, shape=self.resp_acts.shape)\n",
    " \n",
    "        self.policy_ratio = self.resp_acts / self.old_prob_holders\n",
    "        self.clipped_ratio = tf.clip_by_value(self.policy_ratio, 1 - self.clip_val, 1 + self.clip_val)\n",
    "\n",
    "        self.min_loss = tf.minimum(self.policy_ratio * self.advatange_holders, self.clipped_ratio * self.advatange_holders)\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "        # Actor update\n",
    "        \n",
    "        self.kl_divergence = tf.reduce_mean(tf.log(self.old_prob_holders) - tf.log(self.resp_acts))\n",
    "        self.actor_loss = -tf.reduce_mean(self.min_loss)Cycles: Last hour, day, month, year\n",
    "        self.actor_update = self.optimizer.minimize(self.actor_loss)\n",
    "\n",
    "        # Value update\n",
    "        \n",
    "        self.value_loss = tf.reduce_mean(tf.square(self.reward_holders - tf.squeeze(self.value_out_op)))\n",
    "        self.value_update = self.optimizer.minimize(self.value_loss)\n",
    "        \n",
    "        # Combined update\n",
    "        \n",
    "        self.entropy = -tf.reduce_mean(tf.reduce_sum(self.out_op * tf.log(1. / tf.clip_by_value(self.out_op, 1e-8, 1.0)), axis=1))\n",
    "        self.combined_loss = self.actor_loss + self.v_coef * self.value_loss + self.entropy_coef * self.entropy\n",
    "        self.combined_update = self.optimizer.minimize(self.combined_loss)\n",
    "        \n",
    "        def update_func(train_data, train_type=0):\n",
    "            if train_type == 0:\n",
    "                i_rew, li, lf, lp, _, _, _ = self.sess.run([tf.reduce_mean(self.r_i)] + self.losses + self.icm_updates, \n",
    "                                       feed_dict={self.in_op: reshape_train_var(train_data[:, 0]),\n",
    "                                                  self.act_holders: reshape_train_var(train_data[:, 1]),\n",
    "                                                  self.reward_holders: train_data[:, 2],\n",
    "                                                  self.next_obs_holders: reshape_train_var(train_data[:, 3])})\n",
    "                return i_rew, [li, lf, lp]\n",
    "            else:\n",
    "                self.old_probs, self.old_advantages = self.sess.run([self.resp_acts, self.advantages], \n",
    "                                        feed_dict={self.in_op: reshape_train_var(train_data[:, 0]),\n",
    "                                                   self.act_holders: train_data[:, 1],\n",
    "                                                   self.reward_holders: train_data[:, 2]})\n",
    "\n",
    "                for i in range(self.ppo_iters):\n",
    "                    kl_div, _ = self.sess.run([self.kl_divergence, self.combined_update], \n",
    "                                   feed_dict={self.in_op: reshape_train_var(train_data[:, 0]),\n",
    "                                        self.act_holders: reshape_train_var(train_data[:, 1]),\n",
    "                                        self.reward_holders: train_data[:, 2],\n",
    "                                        self.old_prob_holders: self.old_probs,\n",
    "                                        self.advatange_holders: self.old_advantages})\n",
    "                    if kl_div > 1.5 * self.target_kl:\n",
    "                        break\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        return update_func\n",
    "        \n",
    "    def _create_continuous_trainer(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = make_env() # This instance of the environment is only used\n",
    "                              # to get action dimensions\n",
    "in_shape = [42, 42, 4] # Size of reshaped observations\n",
    "\n",
    "# Creating a conv net for the policy and value estimator\n",
    "obs_op = Input(shape=in_shape)\n",
    "conv1 = Conv2D(32, 3, activation='relu')(obs_op)\n",
    "max_pool1 = MaxPool2D(2, 2)(conv1)\n",
    "conv2 = Conv2D(32, 3, activation='relu')(max_pool1)\n",
    "max_pool2 = MaxPool2D(2, 2)(conv2)\n",
    "conv3 = Conv2D(32, 3, activation='relu')(max_pool2)\n",
    "max_pool3 = MaxPool2D(2, 2)(conv3)\n",
    "flattened = Flatten()(max_pool3)\n",
    "dense1 = Dense(64, activation='relu')(flattened)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "dense3 = Dense(128, activation='relu')(dense1)\n",
    "\n",
    "# Output probability distribution over possible actions\n",
    "act_probs_op = Dense(env.action_space.n, activation='softmax')(dense2)\n",
    "\n",
    "# Output value of observed state\n",
    "value_op = Dense(1)(dense3)\n",
    "\n",
    "# Wrap a Proximal Policy Optimization Trainer on top of the network\n",
    "network = IMTrainer(obs_op, act_probs_op, value_op, act_type='discrete', ppo_iters=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 10000 # Total episodes of data to collect\n",
    "max_steps = 1024 # Max number of frames per game\n",
    "batch_size = 16 # Smaller = faster, larger = stabler\n",
    "print_freq = 1 # How many training updates between printing progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_hist = {} # Keeps track of up to 3 previous frames for each agent\n",
    "\n",
    "# Create observation transformation that adds the two last frames on\n",
    "# as two extra dimensions\n",
    "def new_obs_transform(obs, agent_id):\n",
    "    new_frame = preprocess_atari(obs.squeeze(), size=(42, 42)) # First preprocess the new frame\n",
    "    \n",
    "    if agent_id in agent_hist: # Case for a continued episode\n",
    "        agent_hist[agent_id] = agent_hist[agent_id][1:]\n",
    "        agent_hist[agent_id].append(new_frame)\n",
    "    else: # Case for a new episode\n",
    "        agent_hist[agent_id] = [new_frame, new_frame, new_frame, new_frame]\n",
    "    \n",
    "    # Format the data\n",
    "    arr = np.array(agent_hist[agent_id])\n",
    "    return np.swapaxes(arr, 0, 3).squeeze()\n",
    "\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "mtmb = MTMemoryBuffer() # Create a memory buffer to store the episode data\n",
    "\n",
    "# Edit the memory buffer's start_rollout function so that every time\n",
    "# an episode ends, it resets the respective agent's history\n",
    "old_start_rollout = mtmb.start_rollout\n",
    "\n",
    "def new_start_rollout(agent_id):\n",
    "    old_start_rollout(agent_id)\n",
    "    agent_hist.pop(agent_id, None)\n",
    "    \n",
    "mtmb.start_rollout = new_start_rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment controller for generating game data\n",
    "ec = EnvController(make_env, n_threads=4, memory_buffer=mtmb)\n",
    "# Set the preprocessing function for observations\n",
    "ec.set_obs_transform(new_obs_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4851\n",
      "16\n",
      "4096\n",
      "Update #1, Avg Reward (E, I): 1.625, 2.021937370300293\n",
      "16\n",
      "4189\n",
      "Update #2, Avg Reward (E, I): 1.5, 1.9337788820266724\n",
      "16\n",
      "3912\n",
      "Update #3, Avg Reward (E, I): 1.4375, 1.820548176765442\n",
      "16\n",
      "3633\n",
      "Update #4, Avg Reward (E, I): 0.9375, 1.879676103591919\n",
      "16\n",
      "3905\n",
      "Update #5, Avg Reward (E, I): 1.3125, 2.065701723098755\n",
      "16\n",
      "4047\n",
      "Update #6, Avg Reward (E, I): 1.3125, 2.206267833709717\n",
      "16\n",
      "4315\n",
      "Update #7, Avg Reward (E, I): 1.75, 2.5103354454040527\n",
      "16\n",
      "4272\n",
      "Update #8, Avg Reward (E, I): 1.6875, 2.8310184478759766\n",
      "16\n",
      "4139\n",
      "Update #9, Avg Reward (E, I): 1.6875, 3.051278591156006\n",
      "16\n",
      "4380\n",
      "Update #10, Avg Reward (E, I): 1.9375, 3.2508013248443604\n",
      "16\n",
      "3820\n",
      "Update #11, Avg Reward (E, I): 1.1875, 3.364258050918579\n",
      "16\n",
      "4497\n",
      "Update #12, Avg Reward (E, I): 1.9375, 3.744131088256836\n",
      "16\n",
      "3774\n",
      "Update #13, Avg Reward (E, I): 1.125, 4.082278728485107\n",
      "16\n",
      "3728\n",
      "Update #14, Avg Reward (E, I): 1.125, 4.393712043762207\n",
      "16\n",
      "4298\n",
      "Update #15, Avg Reward (E, I): 1.75, 4.868260383605957\n",
      "16\n",
      "3897\n",
      "Update #16, Avg Reward (E, I): 1.25, 5.194439888000488\n",
      "16\n",
      "4169\n",
      "Update #17, Avg Reward (E, I): 1.6875, 5.683988571166992\n",
      "16\n",
      "3799\n",
      "Update #18, Avg Reward (E, I): 1.25, 6.284104347229004\n",
      "16\n",
      "3917\n",
      "Update #19, Avg Reward (E, I): 1.375, 6.770629405975342\n",
      "16\n",
      "4598\n",
      "Update #20, Avg Reward (E, I): 2.125, 7.449681758880615\n",
      "16\n",
      "4598\n",
      "Update #21, Avg Reward (E, I): 2.0, 8.33721923828125\n",
      "16\n",
      "3623\n",
      "Update #22, Avg Reward (E, I): 1.0625, 8.889304161071777\n",
      "16\n",
      "4445\n",
      "Update #23, Avg Reward (E, I): 1.8125, 9.4278564453125\n",
      "16\n",
      "4092\n",
      "Update #24, Avg Reward (E, I): 1.5625, 9.239150047302246\n",
      "16\n",
      "4178\n",
      "Update #25, Avg Reward (E, I): 1.5, 9.084787368774414\n",
      "16\n",
      "4117\n",
      "Update #26, Avg Reward (E, I): 1.6875, 8.969137191772461\n",
      "16\n",
      "4289\n",
      "Update #27, Avg Reward (E, I): 1.875, 9.199929237365723\n",
      "16\n",
      "3999\n",
      "Update #28, Avg Reward (E, I): 1.3125, 10.633500099182129\n",
      "16\n",
      "4391\n",
      "Update #29, Avg Reward (E, I): 1.8125, 12.42897891998291\n",
      "16\n",
      "3904\n",
      "Update #30, Avg Reward (E, I): 1.375, 13.916467666625977\n",
      "16\n",
      "4111\n",
      "Update #31, Avg Reward (E, I): 1.5625, 14.436717987060547\n",
      "16\n",
      "3500\n",
      "Update #32, Avg Reward (E, I): 0.8125, 14.725591659545898\n",
      "16\n",
      "3802\n",
      "Update #33, Avg Reward (E, I): 1.125, 15.135815620422363\n",
      "16\n",
      "3950\n",
      "Update #34, Avg Reward (E, I): 1.3125, 15.467062950134277\n",
      "16\n",
      "4429\n",
      "Update #35, Avg Reward (E, I): 1.875, 15.902314186096191\n",
      "16\n",
      "3832\n",
      "Update #36, Avg Reward (E, I): 1.1875, 16.600723266601562\n",
      "16\n",
      "3617\n",
      "Update #37, Avg Reward (E, I): 1.0, 17.146886825561523\n",
      "16\n",
      "4204\n",
      "Update #38, Avg Reward (E, I): 1.5625, 17.733509063720703\n",
      "16\n",
      "4805\n",
      "Update #39, Avg Reward (E, I): 2.3125, 18.360376358032227\n",
      "16\n",
      "3995\n",
      "Update #40, Avg Reward (E, I): 1.4375, 18.24280548095703\n",
      "16\n",
      "3771\n",
      "Update #41, Avg Reward (E, I): 1.0, 18.299917221069336\n",
      "16\n",
      "4132\n",
      "Update #42, Avg Reward (E, I): 1.6875, 17.949546813964844\n",
      "16\n",
      "4066\n",
      "Update #43, Avg Reward (E, I): 1.5, 18.500965118408203\n",
      "16\n",
      "4612\n",
      "Update #44, Avg Reward (E, I): 2.0, 19.22767448425293\n",
      "16\n",
      "3512\n",
      "Update #45, Avg Reward (E, I): 0.9375, 19.988258361816406\n",
      "16\n",
      "4357\n",
      "Update #46, Avg Reward (E, I): 1.6875, 20.906869888305664\n",
      "16\n",
      "3954\n",
      "Update #47, Avg Reward (E, I): 1.3125, 21.58075714111328\n",
      "16\n",
      "4088\n",
      "Update #48, Avg Reward (E, I): 1.5625, 21.266019821166992\n",
      "16\n",
      "3988\n",
      "Update #49, Avg Reward (E, I): 1.5625, 21.100011825561523\n",
      "16\n",
      "4280\n",
      "Update #50, Avg Reward (E, I): 1.6875, 20.783605575561523\n",
      "16\n",
      "3764\n",
      "Update #51, Avg Reward (E, I): 1.3125, 22.555574417114258\n",
      "16\n",
      "4113\n",
      "Update #52, Avg Reward (E, I): 1.4375, 25.361228942871094\n",
      "16\n",
      "3270\n",
      "Update #53, Avg Reward (E, I): 0.5, 26.853425979614258\n",
      "16\n",
      "3572\n",
      "Update #54, Avg Reward (E, I): 1.0, 26.371183395385742\n",
      "16\n",
      "4364\n",
      "Update #55, Avg Reward (E, I): 1.625, 25.0654239654541\n",
      "16\n",
      "4552\n",
      "Update #56, Avg Reward (E, I): 2.0, 24.76169776916504\n",
      "16\n",
      "3828\n",
      "Update #57, Avg Reward (E, I): 1.3125, 25.52727508544922\n",
      "16\n",
      "4501\n",
      "Update #58, Avg Reward (E, I): 2.125, 26.245328903198242\n",
      "16\n",
      "3410\n",
      "Update #59, Avg Reward (E, I): 0.75, 26.892797470092773\n",
      "16\n",
      "4070\n",
      "Update #60, Avg Reward (E, I): 1.5, 27.61094093322754\n",
      "16\n",
      "4081\n",
      "Update #61, Avg Reward (E, I): 1.4375, 28.199586868286133\n",
      "16\n",
      "3449\n",
      "Update #62, Avg Reward (E, I): 0.75, 28.301939010620117\n",
      "16\n",
      "4439\n",
      "Update #63, Avg Reward (E, I): 1.8125, 28.50914192199707\n",
      "16\n",
      "3974\n",
      "Update #64, Avg Reward (E, I): 1.3125, 28.37563705444336\n",
      "16\n",
      "3988\n",
      "Update #65, Avg Reward (E, I): 1.25, 28.557085037231445\n",
      "16\n",
      "3825\n",
      "Update #66, Avg Reward (E, I): 1.1875, 28.648731231689453\n",
      "16\n",
      "3632\n",
      "Update #67, Avg Reward (E, I): 1.0, 29.110837936401367\n",
      "16\n",
      "4015\n",
      "Update #68, Avg Reward (E, I): 1.375, 29.563697814941406\n",
      "16\n",
      "4223\n",
      "Update #69, Avg Reward (E, I): 1.625, 29.863271713256836\n",
      "16\n",
      "4100\n",
      "Update #70, Avg Reward (E, I): 1.5, 30.053394317626953\n",
      "16\n",
      "3896\n",
      "Update #71, Avg Reward (E, I): 1.25, 30.01061248779297\n",
      "16\n",
      "4120\n",
      "Update #72, Avg Reward (E, I): 1.4375, 30.032529830932617\n",
      "16\n",
      "4018\n",
      "Update #73, Avg Reward (E, I): 1.4375, 30.113636016845703\n",
      "16\n",
      "3733\n",
      "Update #74, Avg Reward (E, I): 1.0625, 30.359024047851562\n",
      "16\n",
      "3884\n",
      "Update #75, Avg Reward (E, I): 1.3125, 30.74238395690918\n",
      "16\n",
      "3987\n",
      "Update #76, Avg Reward (E, I): 1.375, 31.020503997802734\n",
      "16\n",
      "4108\n",
      "Update #77, Avg Reward (E, I): 1.5, 31.14939308166504\n",
      "16\n",
      "3982\n",
      "Update #78, Avg Reward (E, I): 1.4375, 31.151891708374023\n",
      "16\n",
      "4113\n",
      "Update #79, Avg Reward (E, I): 1.5, 31.043018341064453\n",
      "16\n",
      "4081\n",
      "Update #80, Avg Reward (E, I): 1.375, 30.789918899536133\n",
      "16\n",
      "4001\n",
      "Update #81, Avg Reward (E, I): 1.3125, 30.72875213623047\n",
      "16\n",
      "4123\n",
      "Update #82, Avg Reward (E, I): 1.4375, 30.72422218322754\n",
      "16\n",
      "3965\n",
      "Update #83, Avg Reward (E, I): 1.375, 30.878496170043945\n",
      "16\n",
      "3849\n",
      "Update #84, Avg Reward (E, I): 1.3125, 31.192752838134766\n",
      "16\n",
      "4280\n",
      "Update #85, Avg Reward (E, I): 1.6875, 31.798912048339844\n",
      "16\n",
      "4186\n",
      "Update #86, Avg Reward (E, I): 1.625, 32.27058029174805\n",
      "16\n",
      "3915\n",
      "Update #87, Avg Reward (E, I): 1.375, 32.546058654785156\n",
      "16\n",
      "4134\n",
      "Update #88, Avg Reward (E, I): 1.5, 32.517478942871094\n",
      "16\n",
      "3847\n",
      "Update #89, Avg Reward (E, I): 1.1875, 32.47053527832031\n",
      "16\n",
      "4242\n",
      "Update #90, Avg Reward (E, I): 1.6875, 32.54305648803711\n",
      "16\n",
      "3558\n",
      "Update #91, Avg Reward (E, I): 0.9375, 32.42927551269531\n",
      "16\n",
      "3654\n",
      "Update #92, Avg Reward (E, I): 1.0, 32.51267623901367\n",
      "16\n",
      "4038\n",
      "Update #93, Avg Reward (E, I): 1.4375, 32.42654037475586\n",
      "16\n",
      "4314\n",
      "Update #94, Avg Reward (E, I): 1.6875, 32.47994613647461\n",
      "16\n",
      "4160\n",
      "Update #95, Avg Reward (E, I): 1.625, 32.46772766113281\n",
      "16\n",
      "4044\n",
      "Update #96, Avg Reward (E, I): 1.5, 32.47716522216797\n",
      "16\n",
      "3788\n",
      "Update #97, Avg Reward (E, I): 1.3125, 32.502262115478516\n",
      "16\n",
      "4344\n",
      "Update #98, Avg Reward (E, I): 1.8125, 32.54790496826172\n",
      "16\n",
      "4230\n",
      "Update #99, Avg Reward (E, I): 1.625, 32.844783782958984\n",
      "16\n",
      "3992\n",
      "Update #100, Avg Reward (E, I): 1.3125, 33.12159729003906\n",
      "16\n",
      "4147\n",
      "Update #101, Avg Reward (E, I): 1.4375, 33.31161117553711\n",
      "16\n",
      "4421\n",
      "Update #102, Avg Reward (E, I): 1.8125, 33.53676223754883\n",
      "16\n",
      "4110\n",
      "Update #103, Avg Reward (E, I): 1.4375, 33.51602554321289\n",
      "16\n",
      "3644\n",
      "Update #104, Avg Reward (E, I): 1.0625, 33.332855224609375\n",
      "16\n",
      "4258\n",
      "Update #105, Avg Reward (E, I): 1.75, 33.088077545166016\n",
      "16\n",
      "4694\n",
      "Update #106, Avg Reward (E, I): 2.0625, 32.93794631958008\n",
      "16\n",
      "3672\n",
      "Update #107, Avg Reward (E, I): 0.9375, 32.79938888549805\n",
      "16\n",
      "3871\n",
      "Update #108, Avg Reward (E, I): 1.125, 32.76671600341797\n",
      "16\n",
      "4501\n",
      "Update #109, Avg Reward (E, I): 1.875, 32.86427307128906\n",
      "16\n",
      "4222\n",
      "Update #110, Avg Reward (E, I): 1.6875, 32.951438903808594\n",
      "16\n",
      "3607\n",
      "Update #111, Avg Reward (E, I): 0.9375, 32.952064514160156\n",
      "16\n",
      "4076\n",
      "Update #112, Avg Reward (E, I): 1.4375, 32.97037887573242\n",
      "16\n",
      "3864\n",
      "Update #113, Avg Reward (E, I): 1.25, 32.92775344848633\n",
      "16\n",
      "4287\n",
      "Update #114, Avg Reward (E, I): 1.75, 32.97904968261719\n",
      "16\n",
      "3788\n",
      "Update #115, Avg Reward (E, I): 1.1875, 33.051849365234375\n",
      "16\n",
      "3900\n",
      "Update #116, Avg Reward (E, I): 1.3125, 33.077816009521484\n",
      "16\n",
      "3797\n",
      "Update #117, Avg Reward (E, I): 1.0625, 32.71721649169922\n",
      "16\n",
      "4604\n",
      "Update #118, Avg Reward (E, I): 2.125, 32.47813034057617\n",
      "16\n",
      "3944\n",
      "Update #119, Avg Reward (E, I): 1.3125, 32.15834045410156\n",
      "16\n",
      "4226\n",
      "Update #120, Avg Reward (E, I): 1.5625, 32.03483581542969\n",
      "16\n",
      "3860\n",
      "Update #121, Avg Reward (E, I): 1.25, 32.52771759033203\n",
      "16\n",
      "3811\n",
      "Update #122, Avg Reward (E, I): 1.125, 33.04694366455078\n",
      "16\n",
      "3872\n",
      "Update #123, Avg Reward (E, I): 1.25, 32.887149810791016\n",
      "16\n",
      "4322\n",
      "Update #124, Avg Reward (E, I): 1.75, 32.6009521484375\n",
      "16\n",
      "4209\n",
      "Update #125, Avg Reward (E, I): 1.6875, 32.252201080322266\n",
      "16\n",
      "4057\n",
      "Update #126, Avg Reward (E, I): 1.5, 32.48106384277344\n",
      "16\n",
      "3924\n",
      "Update #127, Avg Reward (E, I): 1.375, 33.244510650634766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "3967\n",
      "Update #128, Avg Reward (E, I): 1.375, 33.85519027709961\n",
      "16\n",
      "3731\n",
      "Update #129, Avg Reward (E, I): 1.0625, 33.87940979003906\n",
      "16\n",
      "3599\n",
      "Update #130, Avg Reward (E, I): 0.9375, 33.30869674682617\n",
      "16\n",
      "3842\n",
      "Update #131, Avg Reward (E, I): 1.3125, 32.628517150878906\n",
      "16\n",
      "4605\n",
      "Update #132, Avg Reward (E, I): 2.3125, 32.3742561340332\n",
      "16\n",
      "4203\n",
      "Update #133, Avg Reward (E, I): 1.625, 32.61603927612305\n",
      "16\n",
      "4048\n",
      "Update #134, Avg Reward (E, I): 1.4375, 33.08491897583008\n",
      "16\n",
      "4038\n",
      "Update #135, Avg Reward (E, I): 1.4375, 33.689605712890625\n",
      "16\n",
      "3660\n",
      "Update #136, Avg Reward (E, I): 1.0, 34.126953125\n",
      "16\n",
      "3932\n",
      "Update #137, Avg Reward (E, I): 1.25, 34.26844024658203\n",
      "16\n",
      "3807\n",
      "Update #138, Avg Reward (E, I): 1.1875, 34.28370666503906\n",
      "16\n",
      "3843\n",
      "Update #139, Avg Reward (E, I): 1.1875, 34.33322525024414\n",
      "16\n",
      "3971\n",
      "Update #140, Avg Reward (E, I): 1.4375, 34.68077087402344\n",
      "16\n",
      "4198\n",
      "Update #141, Avg Reward (E, I): 1.5625, 34.949859619140625\n",
      "16\n",
      "4492\n",
      "Update #142, Avg Reward (E, I): 1.875, 35.393009185791016\n",
      "16\n",
      "4095\n",
      "Update #143, Avg Reward (E, I): 1.5, 35.5781135559082\n",
      "16\n",
      "4518\n",
      "Update #144, Avg Reward (E, I): 2.0625, 35.583953857421875\n",
      "16\n",
      "3877\n",
      "Update #145, Avg Reward (E, I): 1.375, 35.465572357177734\n",
      "16\n",
      "4006\n",
      "Update #146, Avg Reward (E, I): 1.5, 35.63966369628906\n",
      "16\n",
      "4282\n",
      "Update #147, Avg Reward (E, I): 1.75, 35.88954544067383\n",
      "16\n",
      "4295\n",
      "Update #148, Avg Reward (E, I): 1.75, 35.844966888427734\n",
      "16\n",
      "4404\n",
      "Update #149, Avg Reward (E, I): 1.875, 35.67755126953125\n",
      "16\n",
      "4563\n",
      "Update #150, Avg Reward (E, I): 2.375, 35.58229064941406\n",
      "16\n",
      "3643\n",
      "Update #151, Avg Reward (E, I): 1.0625, 35.50200653076172\n",
      "16\n",
      "4030\n",
      "Update #152, Avg Reward (E, I): 1.5, 35.7708854675293\n",
      "16\n",
      "3257\n",
      "Update #153, Avg Reward (E, I): 0.625, 35.84056091308594\n",
      "16\n",
      "4372\n",
      "Update #154, Avg Reward (E, I): 1.9375, 35.742286682128906\n",
      "16\n",
      "4225\n",
      "Update #155, Avg Reward (E, I): 1.625, 35.96469497680664\n",
      "16\n",
      "3976\n",
      "Update #156, Avg Reward (E, I): 1.4375, 36.279083251953125\n",
      "16\n",
      "3360\n",
      "Update #157, Avg Reward (E, I): 0.6875, 35.82772445678711\n",
      "16\n",
      "3770\n",
      "Update #158, Avg Reward (E, I): 1.125, 35.12152099609375\n",
      "16\n",
      "3718\n",
      "Update #159, Avg Reward (E, I): 1.125, 35.649112701416016\n",
      "16\n",
      "4286\n",
      "Update #160, Avg Reward (E, I): 1.625, 35.573909759521484\n",
      "16\n",
      "3839\n",
      "Update #161, Avg Reward (E, I): 1.1875, 34.49806213378906\n",
      "16\n",
      "3950\n",
      "Update #162, Avg Reward (E, I): 1.3125, 33.87379837036133\n",
      "16\n",
      "4371\n",
      "Update #163, Avg Reward (E, I): 1.8125, 33.94715881347656\n",
      "16\n",
      "3664\n",
      "Update #164, Avg Reward (E, I): 1.0, 34.28892517089844\n",
      "16\n",
      "4317\n",
      "Update #165, Avg Reward (E, I): 1.5625, 34.7934455871582\n",
      "16\n",
      "4032\n",
      "Update #166, Avg Reward (E, I): 1.5, 35.221614837646484\n",
      "16\n",
      "3994\n",
      "Update #167, Avg Reward (E, I): 1.4375, 35.579559326171875\n",
      "16\n",
      "4032\n",
      "Update #168, Avg Reward (E, I): 1.375, 35.84400939941406\n",
      "16\n",
      "4463\n",
      "Update #169, Avg Reward (E, I): 1.9375, 35.61634826660156\n",
      "16\n",
      "4046\n",
      "Update #170, Avg Reward (E, I): 1.5, 35.21799087524414\n",
      "16\n",
      "3873\n",
      "Update #171, Avg Reward (E, I): 1.1875, 34.778438568115234\n",
      "16\n",
      "4320\n",
      "Update #172, Avg Reward (E, I): 1.75, 34.7364387512207\n",
      "16\n",
      "4100\n",
      "Update #173, Avg Reward (E, I): 1.4375, 35.13624572753906\n",
      "16\n",
      "3987\n",
      "Update #174, Avg Reward (E, I): 1.4375, 35.11643600463867\n",
      "16\n",
      "3871\n",
      "Update #175, Avg Reward (E, I): 1.1875, 35.23048400878906\n",
      "16\n",
      "4096\n",
      "Update #176, Avg Reward (E, I): 1.5, 35.56145095825195\n",
      "16\n",
      "4267\n",
      "Update #177, Avg Reward (E, I): 1.75, 35.91326904296875\n",
      "16\n",
      "3592\n",
      "Update #178, Avg Reward (E, I): 1.0, 35.68508529663086\n",
      "16\n",
      "4047\n",
      "Update #179, Avg Reward (E, I): 1.25, 35.83047103881836\n",
      "16\n",
      "4216\n",
      "Update #180, Avg Reward (E, I): 1.6875, 35.47358322143555\n",
      "16\n",
      "4218\n",
      "Update #181, Avg Reward (E, I): 1.75, 35.258544921875\n",
      "16\n",
      "3709\n",
      "Update #182, Avg Reward (E, I): 1.0625, 35.21976089477539\n",
      "16\n",
      "4386\n",
      "Update #183, Avg Reward (E, I): 1.9375, 35.09939193725586\n",
      "16\n",
      "3954\n",
      "Update #184, Avg Reward (E, I): 1.375, 34.88862228393555\n",
      "16\n",
      "4062\n",
      "Update #185, Avg Reward (E, I): 1.5625, 35.161521911621094\n",
      "16\n",
      "4250\n",
      "Update #186, Avg Reward (E, I): 1.6875, 35.533966064453125\n",
      "16\n",
      "3754\n",
      "Update #187, Avg Reward (E, I): 1.125, 35.664310455322266\n",
      "16\n",
      "4286\n",
      "Update #188, Avg Reward (E, I): 1.75, 35.80050277709961\n",
      "16\n",
      "3665\n",
      "Update #189, Avg Reward (E, I): 1.125, 36.08372116088867\n",
      "16\n",
      "3911\n",
      "Update #190, Avg Reward (E, I): 1.3125, 36.374141693115234\n",
      "16\n",
      "3604\n",
      "Update #191, Avg Reward (E, I): 0.875, 35.94716262817383\n",
      "16\n",
      "3961\n",
      "Update #192, Avg Reward (E, I): 1.4375, 36.07626724243164\n",
      "16\n",
      "3999\n",
      "Update #193, Avg Reward (E, I): 1.375, 36.165321350097656\n",
      "16\n",
      "3523\n",
      "Update #194, Avg Reward (E, I): 0.875, 35.932594299316406\n",
      "16\n",
      "4207\n",
      "Update #195, Avg Reward (E, I): 1.9375, 35.62491989135742\n",
      "16\n",
      "3917\n",
      "Update #196, Avg Reward (E, I): 1.375, 35.64402770996094\n",
      "16\n",
      "4176\n",
      "Update #197, Avg Reward (E, I): 1.5, 35.59891128540039\n",
      "16\n",
      "4451\n",
      "Update #198, Avg Reward (E, I): 1.9375, 35.3363151550293\n",
      "16\n",
      "3993\n",
      "Update #199, Avg Reward (E, I): 1.3125, 35.1859130859375\n",
      "16\n",
      "4418\n",
      "Update #200, Avg Reward (E, I): 1.875, 35.0565071105957\n",
      "16\n",
      "3613\n",
      "Update #201, Avg Reward (E, I): 1.0, 34.85664367675781\n",
      "16\n",
      "4021\n",
      "Update #202, Avg Reward (E, I): 1.4375, 34.48853302001953\n",
      "16\n",
      "4268\n",
      "Update #203, Avg Reward (E, I): 1.625, 34.478267669677734\n",
      "16\n",
      "3769\n",
      "Update #204, Avg Reward (E, I): 1.1875, 34.2480583190918\n",
      "16\n",
      "4102\n",
      "Update #205, Avg Reward (E, I): 1.5625, 34.40632247924805\n",
      "16\n",
      "4085\n",
      "Update #206, Avg Reward (E, I): 1.5625, 34.99357223510742\n",
      "16\n",
      "4277\n",
      "Update #207, Avg Reward (E, I): 1.75, 35.87117385864258\n",
      "16\n",
      "4355\n",
      "Update #208, Avg Reward (E, I): 1.75, 35.915592193603516\n",
      "16\n",
      "4161\n",
      "Update #209, Avg Reward (E, I): 1.75, 35.469200134277344\n",
      "16\n",
      "3505\n",
      "Update #210, Avg Reward (E, I): 0.9375, 35.47953796386719\n",
      "16\n",
      "3868\n",
      "Update #211, Avg Reward (E, I): 1.1875, 35.100826263427734\n",
      "16\n",
      "4345\n",
      "Update #212, Avg Reward (E, I): 1.8125, 35.22221374511719\n",
      "16\n",
      "3870\n",
      "Update #213, Avg Reward (E, I): 1.25, 35.4046630859375\n",
      "16\n",
      "4256\n",
      "Update #214, Avg Reward (E, I): 1.6875, 35.076995849609375\n",
      "16\n",
      "3980\n",
      "Update #215, Avg Reward (E, I): 1.375, 34.387168884277344\n",
      "16\n",
      "3810\n",
      "Update #216, Avg Reward (E, I): 1.25, 34.21516799926758\n",
      "16\n",
      "3786\n",
      "Update #217, Avg Reward (E, I): 1.125, 34.815513610839844\n",
      "16\n",
      "4460\n",
      "Update #218, Avg Reward (E, I): 1.8125, 34.810306549072266\n",
      "16\n",
      "4082\n",
      "Update #219, Avg Reward (E, I): 1.5, 34.95613098144531\n",
      "16\n",
      "4172\n",
      "Update #220, Avg Reward (E, I): 1.75, 35.31223678588867\n",
      "16\n",
      "3775\n",
      "Update #221, Avg Reward (E, I): 1.1875, 35.06991195678711\n",
      "16\n",
      "4209\n",
      "Update #222, Avg Reward (E, I): 1.6875, 34.87187576293945\n",
      "16\n",
      "4379\n",
      "Update #223, Avg Reward (E, I): 1.75, 34.493316650390625\n",
      "16\n",
      "4079\n",
      "Update #224, Avg Reward (E, I): 1.4375, 34.175392150878906\n",
      "16\n",
      "4214\n",
      "Update #225, Avg Reward (E, I): 1.5625, 34.425048828125\n",
      "16\n",
      "3837\n",
      "Update #226, Avg Reward (E, I): 1.25, 34.84831619262695\n",
      "16\n",
      "3772\n",
      "Update #227, Avg Reward (E, I): 1.1875, 35.06904602050781\n",
      "16\n",
      "3838\n",
      "Update #228, Avg Reward (E, I): 1.1875, 35.13159942626953\n",
      "16\n",
      "4049\n",
      "Update #229, Avg Reward (E, I): 1.3125, 35.19785690307617\n",
      "16\n",
      "3923\n",
      "Update #230, Avg Reward (E, I): 1.375, 35.040035247802734\n",
      "16\n",
      "4188\n",
      "Update #231, Avg Reward (E, I): 1.8125, 34.931209564208984\n",
      "16\n",
      "3849\n",
      "Update #232, Avg Reward (E, I): 1.25, 34.61726379394531\n",
      "16\n",
      "3986\n",
      "Update #233, Avg Reward (E, I): 1.3125, 34.730281829833984\n",
      "16\n",
      "3870\n",
      "Update #234, Avg Reward (E, I): 1.1875, 34.462894439697266\n",
      "16\n",
      "4491\n",
      "Update #235, Avg Reward (E, I): 1.875, 34.614967346191406\n",
      "16\n",
      "3887\n",
      "Update #236, Avg Reward (E, I): 1.25, 34.5413932800293\n",
      "16\n",
      "3718\n",
      "Update #237, Avg Reward (E, I): 1.0, 34.51482391357422\n",
      "16\n",
      "4665\n",
      "Update #238, Avg Reward (E, I): 2.0, 34.91731643676758\n",
      "16\n",
      "4221\n",
      "Update #239, Avg Reward (E, I): 1.5625, 35.09508514404297\n",
      "16\n",
      "3567\n",
      "Update #240, Avg Reward (E, I): 0.875, 35.202171325683594\n",
      "16\n",
      "4225\n",
      "Update #241, Avg Reward (E, I): 1.6875, 35.05899429321289\n",
      "16\n",
      "3598\n",
      "Update #242, Avg Reward (E, I): 1.0625, 34.7164192199707\n",
      "16\n",
      "3758\n",
      "Update #243, Avg Reward (E, I): 1.125, 34.829654693603516\n",
      "16\n",
      "4487\n",
      "Update #244, Avg Reward (E, I): 1.9375, 35.208988189697266\n",
      "16\n",
      "4021\n",
      "Update #245, Avg Reward (E, I): 1.4375, 35.11140441894531\n",
      "16\n",
      "3712\n",
      "Update #246, Avg Reward (E, I): 1.125, 34.9686393737793\n",
      "16\n",
      "4165\n",
      "Update #247, Avg Reward (E, I): 1.5625, 34.683006286621094\n",
      "16\n",
      "4296\n",
      "Update #248, Avg Reward (E, I): 1.75, 34.907657623291016\n",
      "16\n",
      "3769\n",
      "Update #249, Avg Reward (E, I): 1.1875, 35.23729705810547\n",
      "16\n",
      "4263\n",
      "Update #250, Avg Reward (E, I): 1.6875, 35.423641204833984\n",
      "16\n",
      "3793\n",
      "Update #251, Avg Reward (E, I): 1.1875, 35.709049224853516\n",
      "16\n",
      "4134\n",
      "Update #252, Avg Reward (E, I): 1.5, 35.93879699707031\n",
      "16\n",
      "3927\n",
      "Update #253, Avg Reward (E, I): 1.3125, 35.95565414428711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4432\n",
      "Update #254, Avg Reward (E, I): 1.875, 35.702964782714844\n",
      "16\n",
      "3786\n",
      "Update #255, Avg Reward (E, I): 1.1875, 35.36470031738281\n",
      "16\n",
      "3984\n",
      "Update #256, Avg Reward (E, I): 1.25, 35.354217529296875\n",
      "16\n",
      "3552\n",
      "Update #257, Avg Reward (E, I): 0.875, 35.389434814453125\n",
      "16\n",
      "4263\n",
      "Update #258, Avg Reward (E, I): 1.75, 35.17220687866211\n",
      "16\n",
      "3848\n",
      "Update #259, Avg Reward (E, I): 1.1875, 35.2606086730957\n",
      "16\n",
      "3827\n",
      "Update #260, Avg Reward (E, I): 1.3125, 35.041194915771484\n",
      "16\n",
      "4201\n",
      "Update #261, Avg Reward (E, I): 1.875, 35.15694046020508\n",
      "16\n",
      "3883\n",
      "Update #262, Avg Reward (E, I): 1.3125, 35.343833923339844\n",
      "16\n",
      "4595\n",
      "Update #263, Avg Reward (E, I): 2.0625, 35.5604248046875\n",
      "16\n",
      "4699\n",
      "Update #264, Avg Reward (E, I): 2.1875, 35.53388214111328\n",
      "16\n",
      "4237\n",
      "Update #265, Avg Reward (E, I): 1.625, 35.47725296020508\n",
      "16\n",
      "3997\n",
      "Update #266, Avg Reward (E, I): 1.375, 35.57422637939453\n",
      "16\n",
      "3767\n",
      "Update #267, Avg Reward (E, I): 1.1875, 35.744754791259766\n",
      "16\n",
      "3809\n",
      "Update #268, Avg Reward (E, I): 1.25, 35.58749771118164\n",
      "16\n",
      "3935\n",
      "Update #269, Avg Reward (E, I): 1.4375, 35.213470458984375\n",
      "16\n",
      "3915\n",
      "Update #270, Avg Reward (E, I): 1.3125, 35.16698455810547\n",
      "16\n",
      "3656\n",
      "Update #271, Avg Reward (E, I): 1.0, 35.141624450683594\n",
      "16\n",
      "3606\n",
      "Update #272, Avg Reward (E, I): 0.9375, 35.077022552490234\n",
      "16\n",
      "4079\n",
      "Update #273, Avg Reward (E, I): 1.5, 35.251529693603516\n",
      "16\n",
      "3558\n",
      "Update #274, Avg Reward (E, I): 0.875, 35.47123336791992\n",
      "16\n",
      "4310\n",
      "Update #275, Avg Reward (E, I): 1.6875, 35.335548400878906\n",
      "16\n",
      "3494\n",
      "Update #276, Avg Reward (E, I): 0.875, 35.08476257324219\n",
      "16\n",
      "3945\n",
      "Update #277, Avg Reward (E, I): 1.3125, 34.92506408691406\n",
      "16\n",
      "3997\n",
      "Update #278, Avg Reward (E, I): 1.375, 34.92668533325195\n",
      "16\n",
      "3994\n",
      "Update #279, Avg Reward (E, I): 1.3125, 34.91484832763672\n",
      "16\n",
      "3974\n",
      "Update #280, Avg Reward (E, I): 1.375, 35.25144958496094\n",
      "16\n",
      "4072\n",
      "Update #281, Avg Reward (E, I): 1.5625, 35.1820182800293\n",
      "16\n",
      "3870\n",
      "Update #282, Avg Reward (E, I): 1.3125, 35.336036682128906\n",
      "16\n",
      "4042\n",
      "Update #283, Avg Reward (E, I): 1.4375, 35.29917907714844\n",
      "16\n",
      "3351\n",
      "Update #284, Avg Reward (E, I): 0.75, 35.29784393310547\n",
      "16\n",
      "4427\n",
      "Update #285, Avg Reward (E, I): 1.875, 35.46254348754883\n",
      "16\n",
      "3875\n",
      "Update #286, Avg Reward (E, I): 1.25, 35.5398063659668\n",
      "16\n",
      "4202\n",
      "Update #287, Avg Reward (E, I): 1.625, 35.47025680541992\n",
      "16\n",
      "3869\n",
      "Update #288, Avg Reward (E, I): 1.3125, 35.54425048828125\n",
      "16\n",
      "4271\n",
      "Update #289, Avg Reward (E, I): 1.625, 35.62995910644531\n",
      "16\n",
      "4634\n",
      "Update #290, Avg Reward (E, I): 2.3125, 35.50117874145508\n",
      "16\n",
      "4033\n",
      "Update #291, Avg Reward (E, I): 1.4375, 35.43959045410156\n",
      "16\n",
      "3846\n",
      "Update #292, Avg Reward (E, I): 1.375, 35.498558044433594\n",
      "16\n",
      "4223\n",
      "Update #293, Avg Reward (E, I): 1.6875, 35.65566635131836\n",
      "16\n",
      "4075\n",
      "Update #294, Avg Reward (E, I): 1.375, 35.49376678466797\n",
      "16\n",
      "4246\n",
      "Update #295, Avg Reward (E, I): 1.5625, 35.55155944824219\n",
      "16\n",
      "4041\n",
      "Update #296, Avg Reward (E, I): 1.5, 35.72135543823242\n",
      "16\n",
      "4096\n",
      "Update #297, Avg Reward (E, I): 1.4375, 36.03866195678711\n",
      "16\n",
      "3853\n",
      "Update #298, Avg Reward (E, I): 1.25, 35.84543991088867\n",
      "16\n",
      "4051\n",
      "Update #299, Avg Reward (E, I): 1.4375, 35.66647720336914\n",
      "16\n",
      "4162\n",
      "Update #300, Avg Reward (E, I): 1.5625, 35.745765686035156\n",
      "16\n",
      "4331\n",
      "Update #301, Avg Reward (E, I): 1.75, 35.953392028808594\n",
      "16\n",
      "3861\n",
      "Update #302, Avg Reward (E, I): 1.3125, 36.124908447265625\n",
      "16\n",
      "3931\n",
      "Update #303, Avg Reward (E, I): 1.3125, 36.3546028137207\n",
      "16\n",
      "4619\n",
      "Update #304, Avg Reward (E, I): 1.9375, 35.91002655029297\n",
      "16\n",
      "4208\n",
      "Update #305, Avg Reward (E, I): 1.625, 35.569393157958984\n",
      "16\n",
      "3966\n",
      "Update #306, Avg Reward (E, I): 1.3125, 35.33578872680664\n",
      "16\n",
      "4458\n",
      "Update #307, Avg Reward (E, I): 1.875, 35.325462341308594\n",
      "16\n",
      "3751\n",
      "Update #308, Avg Reward (E, I): 1.125, 35.55187225341797\n",
      "16\n",
      "3978\n",
      "Update #309, Avg Reward (E, I): 1.375, 35.48151779174805\n",
      "16\n",
      "3742\n",
      "Update #310, Avg Reward (E, I): 1.25, 35.60216522216797\n",
      "16\n",
      "4435\n",
      "Update #311, Avg Reward (E, I): 1.9375, 35.721275329589844\n",
      "16\n",
      "3866\n",
      "Update #312, Avg Reward (E, I): 1.25, 35.839515686035156\n",
      "16\n",
      "4030\n",
      "Update #313, Avg Reward (E, I): 1.4375, 36.0809326171875\n",
      "16\n",
      "4073\n",
      "Update #314, Avg Reward (E, I): 1.625, 36.24937438964844\n",
      "16\n",
      "4349\n",
      "Update #315, Avg Reward (E, I): 1.75, 36.45899200439453\n",
      "16\n",
      "3412\n",
      "Update #316, Avg Reward (E, I): 0.75, 36.43354034423828\n",
      "16\n",
      "3625\n",
      "Update #317, Avg Reward (E, I): 0.875, 36.20267105102539\n",
      "16\n",
      "4359\n",
      "Update #318, Avg Reward (E, I): 1.75, 35.724525451660156\n",
      "16\n",
      "3814\n",
      "Update #319, Avg Reward (E, I): 1.1875, 35.70400619506836\n",
      "16\n",
      "3407\n",
      "Update #320, Avg Reward (E, I): 0.6875, 35.85857391357422\n",
      "16\n",
      "3474\n",
      "Update #321, Avg Reward (E, I): 0.8125, 35.68299865722656\n",
      "16\n",
      "3716\n",
      "Update #322, Avg Reward (E, I): 1.1875, 35.58616638183594\n",
      "16\n",
      "4132\n",
      "Update #323, Avg Reward (E, I): 1.625, 35.45264434814453\n",
      "16\n",
      "4158\n",
      "Update #324, Avg Reward (E, I): 1.625, 35.59874725341797\n",
      "16\n",
      "4573\n",
      "Update #325, Avg Reward (E, I): 2.0, 35.39876937866211\n",
      "16\n",
      "3807\n",
      "Update #326, Avg Reward (E, I): 1.125, 35.58855056762695\n",
      "16\n",
      "3799\n",
      "Update #327, Avg Reward (E, I): 1.125, 35.786170959472656\n",
      "16\n",
      "3610\n",
      "Update #328, Avg Reward (E, I): 1.0, 35.85259246826172\n",
      "16\n",
      "4091\n",
      "Update #329, Avg Reward (E, I): 1.5625, 35.73680114746094\n",
      "16\n",
      "4139\n",
      "Update #330, Avg Reward (E, I): 1.5625, 35.557044982910156\n",
      "16\n",
      "4002\n",
      "Update #331, Avg Reward (E, I): 1.375, 35.547061920166016\n",
      "16\n",
      "4077\n",
      "Update #332, Avg Reward (E, I): 1.625, 35.58150100708008\n",
      "16\n",
      "3772\n",
      "Update #333, Avg Reward (E, I): 1.0625, 35.40306091308594\n",
      "16\n",
      "4156\n",
      "Update #334, Avg Reward (E, I): 1.5625, 35.44812774658203\n",
      "16\n",
      "4025\n",
      "Update #335, Avg Reward (E, I): 1.5, 35.58173751831055\n",
      "16\n",
      "4370\n",
      "Update #336, Avg Reward (E, I): 1.75, 35.64055633544922\n",
      "16\n",
      "3588\n",
      "Update #337, Avg Reward (E, I): 0.875, 35.774234771728516\n",
      "16\n",
      "3941\n",
      "Update #338, Avg Reward (E, I): 1.4375, 35.98332595825195\n",
      "16\n",
      "3945\n",
      "Update #339, Avg Reward (E, I): 1.375, 36.24060821533203\n",
      "16\n",
      "4396\n",
      "Update #340, Avg Reward (E, I): 1.8125, 35.98004150390625\n",
      "16\n",
      "3998\n",
      "Update #341, Avg Reward (E, I): 1.4375, 35.87595748901367\n",
      "16\n",
      "3751\n",
      "Update #342, Avg Reward (E, I): 1.0, 35.84626770019531\n",
      "16\n",
      "4244\n",
      "Update #343, Avg Reward (E, I): 1.6875, 36.055198669433594\n",
      "16\n",
      "4525\n",
      "Update #344, Avg Reward (E, I): 2.0, 35.838993072509766\n",
      "16\n",
      "3855\n",
      "Update #345, Avg Reward (E, I): 1.1875, 35.69934844970703\n",
      "16\n",
      "4281\n",
      "Update #346, Avg Reward (E, I): 1.6875, 35.52052307128906\n",
      "16\n",
      "3935\n",
      "Update #347, Avg Reward (E, I): 1.4375, 35.281822204589844\n",
      "16\n",
      "4283\n",
      "Update #348, Avg Reward (E, I): 1.8125, 35.01279830932617\n",
      "16\n",
      "4254\n",
      "Update #349, Avg Reward (E, I): 1.6875, 34.875030517578125\n",
      "16\n",
      "3827\n",
      "Update #350, Avg Reward (E, I): 1.1875, 35.109825134277344\n",
      "16\n",
      "4067\n",
      "Update #351, Avg Reward (E, I): 1.4375, 35.636985778808594\n",
      "16\n",
      "4454\n",
      "Update #352, Avg Reward (E, I): 1.875, 35.954803466796875\n",
      "16\n",
      "3640\n",
      "Update #353, Avg Reward (E, I): 1.0625, 35.89532470703125\n",
      "16\n",
      "3594\n",
      "Update #354, Avg Reward (E, I): 1.0, 35.78667068481445\n",
      "16\n",
      "4192\n",
      "Update #355, Avg Reward (E, I): 1.5625, 35.953956604003906\n",
      "16\n",
      "4149\n",
      "Update #356, Avg Reward (E, I): 1.625, 35.897918701171875\n",
      "16\n",
      "3666\n",
      "Update #357, Avg Reward (E, I): 0.9375, 35.92657470703125\n",
      "16\n",
      "3611\n",
      "Update #358, Avg Reward (E, I): 0.9375, 35.94437026977539\n",
      "16\n",
      "4099\n",
      "Update #359, Avg Reward (E, I): 1.5, 35.770965576171875\n",
      "16\n",
      "4131\n",
      "Update #360, Avg Reward (E, I): 1.5, 35.670936584472656\n",
      "16\n",
      "3674\n",
      "Update #361, Avg Reward (E, I): 1.125, 35.343170166015625\n",
      "16\n",
      "4479\n",
      "Update #362, Avg Reward (E, I): 2.0, 35.19195556640625\n",
      "16\n",
      "4198\n",
      "Update #363, Avg Reward (E, I): 1.5625, 35.42453384399414\n",
      "16\n",
      "4122\n",
      "Update #364, Avg Reward (E, I): 1.5625, 35.63270568847656\n",
      "16\n",
      "3630\n",
      "Update #365, Avg Reward (E, I): 1.0625, 35.77053451538086\n",
      "16\n",
      "3701\n",
      "Update #366, Avg Reward (E, I): 1.0, 35.65070343017578\n",
      "16\n",
      "4080\n",
      "Update #367, Avg Reward (E, I): 1.5625, 35.75107955932617\n",
      "16\n",
      "4231\n",
      "Update #368, Avg Reward (E, I): 1.875, 35.659141540527344\n",
      "16\n",
      "3776\n",
      "Update #369, Avg Reward (E, I): 1.1875, 35.591609954833984\n",
      "16\n",
      "3819\n",
      "Update #370, Avg Reward (E, I): 1.1875, 35.52210235595703\n",
      "16\n",
      "4136\n",
      "Update #371, Avg Reward (E, I): 1.6875, 35.549163818359375\n",
      "16\n",
      "4724\n",
      "Update #372, Avg Reward (E, I): 2.1875, 35.335994720458984\n",
      "16\n",
      "3490\n",
      "Update #373, Avg Reward (E, I): 0.875, 35.209529876708984\n",
      "16\n",
      "4261\n",
      "Update #374, Avg Reward (E, I): 1.6875, 35.12946319580078\n",
      "16\n",
      "3867\n",
      "Update #375, Avg Reward (E, I): 1.3125, 34.7887077331543\n",
      "16\n",
      "4312\n",
      "Update #376, Avg Reward (E, I): 1.875, 34.86613845825195\n",
      "16\n",
      "3958\n",
      "Update #377, Avg Reward (E, I): 1.3125, 35.08507537841797\n",
      "16\n",
      "4131\n",
      "Update #378, Avg Reward (E, I): 1.5625, 35.64995193481445\n",
      "16\n",
      "4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update #379, Avg Reward (E, I): 1.375, 35.78618621826172\n",
      "16\n",
      "4248\n",
      "Update #380, Avg Reward (E, I): 1.6875, 35.62858963012695\n",
      "16\n",
      "4212\n",
      "Update #381, Avg Reward (E, I): 1.8125, 35.4911994934082\n",
      "16\n",
      "4437\n",
      "Update #382, Avg Reward (E, I): 1.8125, 35.406288146972656\n",
      "16\n",
      "4531\n",
      "Update #383, Avg Reward (E, I): 2.0625, 35.5987663269043\n",
      "16\n",
      "4060\n",
      "Update #384, Avg Reward (E, I): 1.4375, 35.69038009643555\n",
      "16\n",
      "3827\n",
      "Update #385, Avg Reward (E, I): 1.4375, 35.60451126098633\n",
      "16\n",
      "4221\n",
      "Update #386, Avg Reward (E, I): 1.5625, 35.636810302734375\n",
      "16\n",
      "4040\n",
      "Update #387, Avg Reward (E, I): 1.375, 35.652103424072266\n",
      "16\n",
      "3828\n",
      "Update #388, Avg Reward (E, I): 1.25, 35.33037567138672\n",
      "16\n",
      "4589\n",
      "Update #389, Avg Reward (E, I): 2.125, 35.33203125\n",
      "16\n",
      "3775\n",
      "Update #390, Avg Reward (E, I): 1.125, 35.67604446411133\n",
      "16\n",
      "3502\n",
      "Update #391, Avg Reward (E, I): 0.8125, 35.63094711303711\n",
      "16\n",
      "3788\n",
      "Update #392, Avg Reward (E, I): 1.1875, 35.704742431640625\n",
      "16\n",
      "4056\n",
      "Update #393, Avg Reward (E, I): 1.375, 35.57771301269531\n",
      "16\n",
      "4423\n",
      "Update #394, Avg Reward (E, I): 1.9375, 35.36537170410156\n",
      "16\n",
      "3523\n",
      "Update #395, Avg Reward (E, I): 0.875, 35.37152862548828\n",
      "16\n",
      "3886\n",
      "Update #396, Avg Reward (E, I): 1.25, 35.436763763427734\n",
      "16\n",
      "4222\n",
      "Update #397, Avg Reward (E, I): 1.6875, 35.43486785888672\n",
      "16\n",
      "4049\n",
      "Update #398, Avg Reward (E, I): 1.4375, 35.40154266357422\n",
      "16\n",
      "4087\n",
      "Update #399, Avg Reward (E, I): 1.5, 35.803035736083984\n",
      "16\n",
      "4540\n",
      "Update #400, Avg Reward (E, I): 1.9375, 35.8221435546875\n",
      "16\n",
      "3573\n",
      "Update #401, Avg Reward (E, I): 0.875, 36.00707244873047\n",
      "16\n",
      "3690\n",
      "Update #402, Avg Reward (E, I): 1.0625, 35.63325881958008\n",
      "16\n",
      "4172\n",
      "Update #403, Avg Reward (E, I): 1.6875, 35.153106689453125\n",
      "16\n",
      "4396\n",
      "Update #404, Avg Reward (E, I): 1.9375, 35.194725036621094\n",
      "16\n",
      "4535\n",
      "Update #405, Avg Reward (E, I): 2.0625, 35.41171646118164\n",
      "16\n",
      "3572\n",
      "Update #406, Avg Reward (E, I): 0.875, 35.32905197143555\n",
      "16\n",
      "4312\n",
      "Update #407, Avg Reward (E, I): 1.625, 35.31218719482422\n",
      "16\n",
      "4312\n",
      "Update #408, Avg Reward (E, I): 1.625, 35.20444107055664\n",
      "16\n",
      "3883\n",
      "Update #409, Avg Reward (E, I): 1.3125, 35.167816162109375\n",
      "16\n",
      "3472\n",
      "Update #410, Avg Reward (E, I): 0.8125, 34.973514556884766\n",
      "16\n",
      "3903\n",
      "Update #411, Avg Reward (E, I): 1.25, 34.88859176635742\n",
      "16\n",
      "3726\n",
      "Update #412, Avg Reward (E, I): 1.0625, 35.01252365112305\n",
      "16\n",
      "4397\n",
      "Update #413, Avg Reward (E, I): 1.75, 34.997161865234375\n",
      "16\n",
      "4352\n",
      "Update #414, Avg Reward (E, I): 1.75, 35.17708206176758\n",
      "16\n",
      "3741\n",
      "Update #415, Avg Reward (E, I): 1.125, 35.02029037475586\n",
      "16\n",
      "4412\n",
      "Update #416, Avg Reward (E, I): 1.8125, 35.19786071777344\n",
      "16\n",
      "4283\n",
      "Update #417, Avg Reward (E, I): 1.75, 35.22657775878906\n",
      "16\n",
      "3621\n",
      "Update #418, Avg Reward (E, I): 1.0, 35.33369064331055\n",
      "16\n",
      "3816\n",
      "Update #419, Avg Reward (E, I): 1.25, 35.42267990112305\n",
      "16\n",
      "3974\n",
      "Update #420, Avg Reward (E, I): 1.3125, 35.63923263549805\n",
      "16\n",
      "3823\n",
      "Update #421, Avg Reward (E, I): 1.1875, 35.57966995239258\n",
      "16\n",
      "3919\n",
      "Update #422, Avg Reward (E, I): 1.3125, 35.64070129394531\n",
      "16\n",
      "4156\n",
      "Update #423, Avg Reward (E, I): 1.625, 35.7710075378418\n",
      "16\n",
      "4139\n",
      "Update #424, Avg Reward (E, I): 1.5625, 35.75325393676758\n",
      "16\n",
      "3789\n",
      "Update #425, Avg Reward (E, I): 1.1875, 35.95090103149414\n",
      "16\n",
      "4179\n",
      "Update #426, Avg Reward (E, I): 1.5, 35.638309478759766\n",
      "16\n",
      "3411\n",
      "Update #427, Avg Reward (E, I): 0.75, 35.598751068115234\n",
      "16\n",
      "4108\n",
      "Update #428, Avg Reward (E, I): 1.5625, 35.62131881713867\n",
      "16\n",
      "3686\n",
      "Update #429, Avg Reward (E, I): 1.125, 35.42854690551758\n",
      "16\n",
      "3695\n",
      "Update #430, Avg Reward (E, I): 1.0625, 35.29350662231445\n",
      "16\n",
      "4445\n",
      "Update #431, Avg Reward (E, I): 1.875, 35.25440979003906\n",
      "16\n",
      "4153\n",
      "Update #432, Avg Reward (E, I): 1.5, 35.2193489074707\n",
      "16\n",
      "3981\n",
      "Update #433, Avg Reward (E, I): 1.3125, 35.18167495727539\n",
      "16\n",
      "3747\n",
      "Update #434, Avg Reward (E, I): 1.1875, 35.10321044921875\n",
      "16\n",
      "3770\n",
      "Update #435, Avg Reward (E, I): 1.1875, 35.123939514160156\n",
      "16\n",
      "4356\n",
      "Update #436, Avg Reward (E, I): 1.6875, 35.2966423034668\n",
      "16\n",
      "4350\n",
      "Update #437, Avg Reward (E, I): 1.8125, 35.49961853027344\n",
      "16\n",
      "3847\n",
      "Update #438, Avg Reward (E, I): 1.375, 35.51650619506836\n",
      "16\n",
      "4075\n",
      "Update #439, Avg Reward (E, I): 1.5, 35.589107513427734\n",
      "16\n",
      "4345\n",
      "Update #440, Avg Reward (E, I): 1.8125, 35.63894271850586\n",
      "16\n",
      "4215\n",
      "Update #441, Avg Reward (E, I): 1.625, 35.65971755981445\n",
      "16\n",
      "4370\n",
      "Update #442, Avg Reward (E, I): 1.8125, 35.650020599365234\n",
      "16\n",
      "4226\n",
      "Update #443, Avg Reward (E, I): 1.75, 35.81001663208008\n",
      "16\n",
      "4237\n",
      "Update #444, Avg Reward (E, I): 1.6875, 35.92741012573242\n",
      "16\n",
      "3799\n",
      "Update #445, Avg Reward (E, I): 1.125, 35.737667083740234\n",
      "16\n",
      "3656\n",
      "Update #446, Avg Reward (E, I): 1.0625, 35.67689514160156\n",
      "16\n",
      "3561\n",
      "Update #447, Avg Reward (E, I): 0.9375, 35.72559356689453\n",
      "16\n",
      "4140\n",
      "Update #448, Avg Reward (E, I): 1.5, 35.74452209472656\n",
      "16\n",
      "4376\n",
      "Update #449, Avg Reward (E, I): 1.8125, 35.837890625\n",
      "16\n",
      "4272\n",
      "Update #450, Avg Reward (E, I): 1.75, 35.744895935058594\n",
      "16\n",
      "3823\n",
      "Update #451, Avg Reward (E, I): 1.25, 35.57767105102539\n",
      "16\n",
      "4050\n",
      "Update #452, Avg Reward (E, I): 1.5625, 35.49203109741211\n",
      "16\n",
      "3627\n",
      "Update #453, Avg Reward (E, I): 1.0, 35.39347839355469\n",
      "16\n",
      "3967\n",
      "Update #454, Avg Reward (E, I): 1.375, 35.51256561279297\n",
      "16\n",
      "3697\n",
      "Update #455, Avg Reward (E, I): 1.0625, 35.682655334472656\n",
      "16\n",
      "3664\n",
      "Update #456, Avg Reward (E, I): 1.125, 35.5299186706543\n",
      "16\n",
      "4077\n",
      "Update #457, Avg Reward (E, I): 1.4375, 35.572669982910156\n",
      "16\n",
      "3737\n",
      "Update #458, Avg Reward (E, I): 1.1875, 35.5169563293457\n",
      "16\n",
      "3729\n",
      "Update #459, Avg Reward (E, I): 1.0625, 35.58580780029297\n",
      "16\n",
      "4351\n",
      "Update #460, Avg Reward (E, I): 1.6875, 35.64104080200195\n",
      "16\n",
      "3942\n",
      "Update #461, Avg Reward (E, I): 1.375, 35.70870590209961\n",
      "16\n",
      "4074\n",
      "Update #462, Avg Reward (E, I): 1.5, 35.60360336303711\n",
      "16\n",
      "4292\n",
      "Update #463, Avg Reward (E, I): 1.6875, 35.56065368652344\n",
      "16\n",
      "4269\n",
      "Update #464, Avg Reward (E, I): 1.625, 35.34803009033203\n",
      "16\n",
      "3804\n",
      "Update #465, Avg Reward (E, I): 1.25, 35.319366455078125\n",
      "16\n",
      "3794\n",
      "Update #466, Avg Reward (E, I): 1.1875, 35.30295944213867\n",
      "16\n",
      "4657\n",
      "Update #467, Avg Reward (E, I): 2.0625, 35.49767303466797\n",
      "16\n",
      "4194\n",
      "Update #468, Avg Reward (E, I): 1.625, 35.544029235839844\n",
      "16\n",
      "4077\n",
      "Update #469, Avg Reward (E, I): 1.4375, 35.452659606933594\n",
      "16\n",
      "3370\n",
      "Update #470, Avg Reward (E, I): 0.75, 35.560546875\n",
      "16\n",
      "4477\n",
      "Update #471, Avg Reward (E, I): 2.0, 35.485679626464844\n",
      "16\n",
      "4255\n",
      "Update #472, Avg Reward (E, I): 1.6875, 35.4799919128418\n",
      "16\n",
      "3807\n",
      "Update #473, Avg Reward (E, I): 1.1875, 35.77992248535156\n",
      "16\n",
      "4124\n",
      "Update #474, Avg Reward (E, I): 1.5, 35.87586212158203\n",
      "16\n",
      "4250\n",
      "Update #475, Avg Reward (E, I): 1.5625, 35.70925521850586\n",
      "16\n",
      "3889\n",
      "Update #476, Avg Reward (E, I): 1.3125, 35.6779899597168\n",
      "16\n",
      "3892\n",
      "Update #477, Avg Reward (E, I): 1.3125, 35.561283111572266\n",
      "16\n",
      "4175\n",
      "Update #478, Avg Reward (E, I): 1.5625, 35.65810012817383\n",
      "16\n",
      "4281\n",
      "Update #479, Avg Reward (E, I): 1.8125, 35.75510787963867\n",
      "16\n",
      "3822\n",
      "Update #480, Avg Reward (E, I): 1.1875, 35.91212844848633\n",
      "16\n",
      "3608\n",
      "Update #481, Avg Reward (E, I): 0.9375, 35.775604248046875\n",
      "16\n",
      "3675\n",
      "Update #482, Avg Reward (E, I): 1.0625, 35.68305206298828\n",
      "16\n",
      "3901\n",
      "Update #483, Avg Reward (E, I): 1.3125, 35.58175277709961\n",
      "16\n",
      "3964\n",
      "Update #484, Avg Reward (E, I): 1.5, 35.691280364990234\n",
      "16\n",
      "3427\n",
      "Update #485, Avg Reward (E, I): 0.8125, 35.576656341552734\n",
      "16\n",
      "4060\n",
      "Update #486, Avg Reward (E, I): 1.375, 35.65736389160156\n",
      "16\n",
      "4084\n",
      "Update #487, Avg Reward (E, I): 1.5, 35.58611297607422\n",
      "16\n",
      "4667\n",
      "Update #488, Avg Reward (E, I): 2.25, 35.53446960449219\n",
      "16\n",
      "3819\n",
      "Update #489, Avg Reward (E, I): 1.25, 35.3684196472168\n",
      "16\n",
      "4028\n",
      "Update #490, Avg Reward (E, I): 1.5, 35.09079360961914\n",
      "16\n",
      "4162\n",
      "Update #491, Avg Reward (E, I): 1.5625, 35.098716735839844\n",
      "16\n",
      "4698\n",
      "Update #492, Avg Reward (E, I): 2.0625, 35.38456344604492\n",
      "16\n",
      "4272\n",
      "Update #493, Avg Reward (E, I): 1.625, 35.79430389404297\n",
      "16\n",
      "4143\n",
      "Update #494, Avg Reward (E, I): 1.5625, 35.902313232421875\n",
      "16\n",
      "3662\n",
      "Update #495, Avg Reward (E, I): 0.9375, 35.831565856933594\n",
      "16\n",
      "3946\n",
      "Update #496, Avg Reward (E, I): 1.375, 35.74822998046875\n",
      "16\n",
      "4219\n",
      "Update #497, Avg Reward (E, I): 1.625, 35.62958908081055\n",
      "16\n",
      "4456\n",
      "Update #498, Avg Reward (E, I): 1.875, 35.503562927246094\n",
      "16\n",
      "3980\n",
      "Update #499, Avg Reward (E, I): 1.375, 35.401031494140625\n",
      "16\n",
      "3660\n",
      "Update #500, Avg Reward (E, I): 1.125, 35.26832962036133\n",
      "16\n",
      "3561\n",
      "Update #501, Avg Reward (E, I): 1.0, 35.432594299316406\n",
      "16\n",
      "3997\n",
      "Update #502, Avg Reward (E, I): 1.5, 35.385921478271484\n",
      "16\n",
      "4124\n",
      "Update #503, Avg Reward (E, I): 1.4375, 35.16144943237305\n",
      "16\n",
      "4322\n",
      "Update #504, Avg Reward (E, I): 1.75, 35.261837005615234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4129\n",
      "Update #505, Avg Reward (E, I): 1.5, 35.446678161621094\n",
      "16\n",
      "3622\n",
      "Update #506, Avg Reward (E, I): 1.0, 35.52969741821289\n",
      "16\n",
      "3967\n",
      "Update #507, Avg Reward (E, I): 1.4375, 35.49864959716797\n",
      "16\n",
      "3685\n",
      "Update #508, Avg Reward (E, I): 1.125, 35.24808120727539\n",
      "16\n",
      "4756\n",
      "Update #509, Avg Reward (E, I): 2.25, 35.181026458740234\n",
      "16\n",
      "4395\n",
      "Update #510, Avg Reward (E, I): 2.0, 35.32768630981445\n",
      "16\n",
      "4208\n",
      "Update #511, Avg Reward (E, I): 1.5, 35.5011100769043\n",
      "16\n",
      "4365\n",
      "Update #512, Avg Reward (E, I): 1.875, 35.57898712158203\n",
      "16\n",
      "3900\n",
      "Update #513, Avg Reward (E, I): 1.375, 35.77070617675781\n",
      "16\n",
      "3938\n",
      "Update #514, Avg Reward (E, I): 1.3125, 35.789005279541016\n",
      "16\n",
      "3532\n",
      "Update #515, Avg Reward (E, I): 0.875, 35.88114929199219\n",
      "16\n",
      "4161\n",
      "Update #516, Avg Reward (E, I): 1.5, 35.97163009643555\n",
      "16\n",
      "3807\n",
      "Update #517, Avg Reward (E, I): 1.25, 35.81123352050781\n",
      "16\n",
      "3853\n",
      "Update #518, Avg Reward (E, I): 1.25, 35.68925094604492\n",
      "16\n",
      "3505\n",
      "Update #519, Avg Reward (E, I): 0.875, 35.54646301269531\n",
      "16\n",
      "3968\n",
      "Update #520, Avg Reward (E, I): 1.4375, 35.64899826049805\n",
      "16\n",
      "4474\n",
      "Update #521, Avg Reward (E, I): 1.875, 35.14595031738281\n",
      "16\n",
      "3978\n",
      "Update #522, Avg Reward (E, I): 1.375, 35.018028259277344\n",
      "16\n",
      "3859\n",
      "Update #523, Avg Reward (E, I): 1.25, 35.04722213745117\n",
      "16\n",
      "4267\n",
      "Update #524, Avg Reward (E, I): 1.8125, 35.320587158203125\n",
      "16\n",
      "4044\n",
      "Update #525, Avg Reward (E, I): 1.4375, 35.50428009033203\n",
      "16\n",
      "4276\n",
      "Update #526, Avg Reward (E, I): 1.75, 35.57752990722656\n",
      "16\n",
      "4177\n",
      "Update #527, Avg Reward (E, I): 1.625, 35.929996490478516\n",
      "16\n",
      "3890\n",
      "Update #528, Avg Reward (E, I): 1.375, 36.15874481201172\n",
      "16\n",
      "3910\n",
      "Update #529, Avg Reward (E, I): 1.3125, 36.03815460205078\n",
      "16\n",
      "3736\n",
      "Update #530, Avg Reward (E, I): 1.25, 36.28083038330078\n",
      "16\n",
      "3711\n",
      "Update #531, Avg Reward (E, I): 1.125, 36.24907684326172\n",
      "16\n",
      "3927\n",
      "Update #532, Avg Reward (E, I): 1.1875, 36.05180358886719\n",
      "16\n",
      "4384\n",
      "Update #533, Avg Reward (E, I): 1.9375, 35.78804016113281\n",
      "16\n",
      "3628\n",
      "Update #534, Avg Reward (E, I): 1.0625, 35.88752746582031\n",
      "16\n",
      "3681\n",
      "Update #535, Avg Reward (E, I): 1.0625, 35.53529357910156\n",
      "16\n",
      "3932\n",
      "Update #536, Avg Reward (E, I): 1.3125, 35.43129348754883\n",
      "16\n",
      "3667\n",
      "Update #537, Avg Reward (E, I): 1.1875, 35.551239013671875\n",
      "16\n",
      "3918\n",
      "Update #538, Avg Reward (E, I): 1.25, 35.637657165527344\n",
      "16\n",
      "3279\n",
      "Update #539, Avg Reward (E, I): 0.6875, 35.55318832397461\n",
      "16\n",
      "3829\n",
      "Update #540, Avg Reward (E, I): 1.25, 35.46840286254883\n",
      "16\n",
      "4454\n",
      "Update #541, Avg Reward (E, I): 1.9375, 35.369503021240234\n",
      "16\n",
      "3627\n",
      "Update #542, Avg Reward (E, I): 0.9375, 35.46409225463867\n",
      "16\n",
      "4000\n",
      "Update #543, Avg Reward (E, I): 1.5, 35.562435150146484\n",
      "16\n",
      "3813\n",
      "Update #544, Avg Reward (E, I): 1.25, 35.61223220825195\n",
      "16\n",
      "3904\n",
      "Update #545, Avg Reward (E, I): 1.1875, 35.51881408691406\n",
      "16\n",
      "4127\n",
      "Update #546, Avg Reward (E, I): 1.5625, 35.3200569152832\n",
      "16\n",
      "3522\n",
      "Update #547, Avg Reward (E, I): 0.8125, 35.32676696777344\n",
      "16\n",
      "4525\n",
      "Update #548, Avg Reward (E, I): 1.8125, 35.303367614746094\n",
      "16\n",
      "4298\n",
      "Update #549, Avg Reward (E, I): 1.625, 35.34904098510742\n",
      "16\n",
      "4183\n",
      "Update #550, Avg Reward (E, I): 1.5625, 35.5052375793457\n",
      "16\n",
      "3732\n",
      "Update #551, Avg Reward (E, I): 1.125, 35.50776672363281\n",
      "16\n",
      "4689\n",
      "Update #552, Avg Reward (E, I): 2.1875, 35.55364227294922\n",
      "16\n",
      "3255\n",
      "Update #553, Avg Reward (E, I): 0.5, 35.58702087402344\n",
      "16\n",
      "4020\n",
      "Update #554, Avg Reward (E, I): 1.4375, 35.649715423583984\n",
      "16\n",
      "3771\n",
      "Update #555, Avg Reward (E, I): 1.1875, 35.61499786376953\n",
      "16\n",
      "4048\n",
      "Update #556, Avg Reward (E, I): 1.5, 35.73577117919922\n",
      "16\n",
      "4040\n",
      "Update #557, Avg Reward (E, I): 1.4375, 35.71026611328125\n",
      "16\n",
      "3938\n",
      "Update #558, Avg Reward (E, I): 1.3125, 35.837318420410156\n",
      "16\n",
      "3924\n",
      "Update #559, Avg Reward (E, I): 1.5, 35.60214614868164\n",
      "16\n",
      "3832\n",
      "Update #560, Avg Reward (E, I): 1.1875, 35.26456832885742\n",
      "16\n",
      "3887\n",
      "Update #561, Avg Reward (E, I): 1.375, 35.42594528198242\n",
      "16\n",
      "4044\n",
      "Update #562, Avg Reward (E, I): 1.4375, 35.72352981567383\n",
      "16\n",
      "3847\n",
      "Update #563, Avg Reward (E, I): 1.1875, 35.79880142211914\n",
      "16\n",
      "4110\n",
      "Update #564, Avg Reward (E, I): 1.625, 35.63516616821289\n",
      "16\n",
      "4488\n",
      "Update #565, Avg Reward (E, I): 1.8125, 35.38051986694336\n",
      "16\n",
      "4147\n",
      "Update #566, Avg Reward (E, I): 1.5625, 35.358001708984375\n",
      "16\n",
      "3875\n",
      "Update #567, Avg Reward (E, I): 1.1875, 35.524932861328125\n",
      "16\n",
      "3734\n",
      "Update #568, Avg Reward (E, I): 1.0625, 35.82252502441406\n",
      "16\n",
      "3967\n",
      "Update #569, Avg Reward (E, I): 1.3125, 35.91501998901367\n",
      "16\n",
      "3923\n",
      "Update #570, Avg Reward (E, I): 1.3125, 36.1264762878418\n",
      "16\n",
      "3679\n",
      "Update #571, Avg Reward (E, I): 1.0625, 35.913570404052734\n",
      "16\n",
      "4053\n",
      "Update #572, Avg Reward (E, I): 1.375, 35.76552200317383\n",
      "16\n",
      "4248\n",
      "Update #573, Avg Reward (E, I): 1.625, 35.62416076660156\n",
      "16\n",
      "4148\n",
      "Update #574, Avg Reward (E, I): 1.625, 35.570335388183594\n",
      "16\n",
      "3642\n",
      "Update #575, Avg Reward (E, I): 1.0625, 35.57976150512695\n",
      "16\n",
      "3946\n",
      "Update #576, Avg Reward (E, I): 1.375, 35.528133392333984\n",
      "16\n",
      "3514\n",
      "Update #577, Avg Reward (E, I): 0.8125, 35.53804397583008\n",
      "16\n",
      "3681\n",
      "Update #578, Avg Reward (E, I): 1.0, 35.32450485229492\n",
      "16\n",
      "4951\n",
      "Update #579, Avg Reward (E, I): 2.5, 35.25975036621094\n",
      "16\n",
      "4124\n",
      "Update #580, Avg Reward (E, I): 1.5, 35.09899139404297\n",
      "16\n",
      "3860\n",
      "Update #581, Avg Reward (E, I): 1.25, 35.01018142700195\n",
      "16\n",
      "4534\n",
      "Update #582, Avg Reward (E, I): 2.125, 35.00996017456055\n",
      "16\n",
      "4259\n",
      "Update #583, Avg Reward (E, I): 1.75, 35.18235778808594\n",
      "16\n",
      "3849\n",
      "Update #584, Avg Reward (E, I): 1.25, 35.304386138916016\n",
      "16\n",
      "3771\n",
      "Update #585, Avg Reward (E, I): 1.125, 35.507781982421875\n",
      "16\n",
      "4245\n",
      "Update #586, Avg Reward (E, I): 1.5625, 35.411651611328125\n",
      "16\n",
      "3841\n",
      "Update #587, Avg Reward (E, I): 1.25, 35.19424819946289\n",
      "16\n",
      "3740\n",
      "Update #588, Avg Reward (E, I): 1.125, 35.26227569580078\n",
      "16\n",
      "3265\n",
      "Update #589, Avg Reward (E, I): 0.5, 35.313011169433594\n",
      "16\n",
      "3932\n",
      "Update #590, Avg Reward (E, I): 1.375, 35.51092529296875\n",
      "16\n",
      "4488\n",
      "Update #591, Avg Reward (E, I): 1.8125, 35.589500427246094\n",
      "16\n",
      "3375\n",
      "Update #592, Avg Reward (E, I): 0.6875, 35.56276321411133\n",
      "16\n",
      "3430\n",
      "Update #593, Avg Reward (E, I): 0.8125, 35.21570587158203\n",
      "16\n",
      "4252\n",
      "Update #594, Avg Reward (E, I): 1.625, 35.04964828491211\n",
      "16\n",
      "4113\n",
      "Update #595, Avg Reward (E, I): 1.5625, 34.89360046386719\n",
      "16\n",
      "3606\n",
      "Update #596, Avg Reward (E, I): 1.0, 35.01248550415039\n",
      "16\n",
      "4066\n",
      "Update #597, Avg Reward (E, I): 1.375, 35.144474029541016\n",
      "16\n",
      "3853\n",
      "Update #598, Avg Reward (E, I): 1.25, 35.35791015625\n",
      "16\n",
      "4235\n",
      "Update #599, Avg Reward (E, I): 1.6875, 35.338253021240234\n",
      "16\n",
      "3476\n",
      "Update #600, Avg Reward (E, I): 0.875, 35.15083312988281\n",
      "16\n",
      "4194\n",
      "Update #601, Avg Reward (E, I): 1.625, 35.22007369995117\n",
      "16\n",
      "4332\n",
      "Update #602, Avg Reward (E, I): 1.75, 35.302711486816406\n",
      "16\n",
      "4388\n",
      "Update #603, Avg Reward (E, I): 1.8125, 35.442222595214844\n",
      "16\n",
      "3870\n",
      "Update #604, Avg Reward (E, I): 1.25, 35.55508041381836\n",
      "16\n",
      "3747\n",
      "Update #605, Avg Reward (E, I): 1.125, 35.69110107421875\n",
      "16\n",
      "4214\n",
      "Update #606, Avg Reward (E, I): 1.9375, 35.65359115600586\n",
      "16\n",
      "3932\n",
      "Update #607, Avg Reward (E, I): 1.5, 35.63833999633789\n",
      "16\n",
      "4456\n",
      "Update #608, Avg Reward (E, I): 1.6875, 35.398651123046875\n",
      "16\n",
      "3685\n",
      "Update #609, Avg Reward (E, I): 1.0, 35.19704818725586\n",
      "16\n",
      "3674\n",
      "Update #610, Avg Reward (E, I): 1.0625, 35.25196075439453\n",
      "16\n",
      "3915\n",
      "Update #611, Avg Reward (E, I): 1.3125, 35.25214385986328\n",
      "16\n",
      "4240\n",
      "Update #612, Avg Reward (E, I): 1.625, 35.241336822509766\n",
      "16\n",
      "4019\n",
      "Update #613, Avg Reward (E, I): 1.375, 35.109275817871094\n",
      "16\n",
      "3864\n",
      "Update #614, Avg Reward (E, I): 1.1875, 35.070465087890625\n",
      "16\n",
      "4046\n",
      "Update #615, Avg Reward (E, I): 1.375, 35.07970428466797\n",
      "16\n",
      "4062\n",
      "Update #616, Avg Reward (E, I): 1.4375, 34.99592971801758\n",
      "16\n",
      "3910\n",
      "Update #617, Avg Reward (E, I): 1.375, 35.1340217590332\n",
      "16\n",
      "3860\n",
      "Update #618, Avg Reward (E, I): 1.25, 35.16069793701172\n",
      "16\n",
      "3798\n",
      "Update #619, Avg Reward (E, I): 1.1875, 35.11079025268555\n",
      "16\n",
      "4106\n",
      "Update #620, Avg Reward (E, I): 1.5, 35.00981521606445\n",
      "16\n",
      "4298\n",
      "Update #621, Avg Reward (E, I): 1.75, 34.95352554321289\n",
      "16\n",
      "4354\n",
      "Update #622, Avg Reward (E, I): 1.8125, 35.17500686645508\n",
      "16\n",
      "3971\n",
      "Update #623, Avg Reward (E, I): 1.3125, 35.211185455322266\n",
      "16\n",
      "3916\n",
      "Update #624, Avg Reward (E, I): 1.25, 35.09788131713867\n"
     ]
    }
   ],
   "source": [
    "update_rewards = []\n",
    "update_i_rewards = []\n",
    "train_type = 0\n",
    "render = False\n",
    "\n",
    "for i in range(int(n_episodes / batch_size)):\n",
    "    ec.sim_episodes(network, batch_size, max_steps) # Simualate env to generate data\n",
    "    update_rewards.append(ec.get_avg_reward()) # Append rewards to reward tracker list\n",
    "    \n",
    "    print(sum([len(x) for x in ec.mb.rollouts]))\n",
    "    if sum([len(x) for x in ec.mb.rollouts]) > 10000:\n",
    "        rollouts = ec.mb.rollouts\n",
    "        \n",
    "    dat = ec.get_data() # Get all the data gathered\n",
    "#     if train_type == 0 and len(update_i_rewards) >= 4 and update_i_rewards[-1] <= update_i_rewards[-2] and \\\n",
    "#        update_i_rewards[-1] <= update_i_rewards[-3] and update_i_rewards[-1] <= update_i_rewards[-4]:\n",
    "#         print('Switching to PPO training')\n",
    "#         train_type = 1\n",
    "    \n",
    "    if train_type == 0:\n",
    "        i_rew, losses = network.train(dat, train_type=0) # Train the network with PPO\n",
    "        update_i_rewards.append(i_rew)\n",
    "\n",
    "        if i != 0 and i % print_freq == 0:\n",
    "            print(f'Update #{i}, Avg Reward (E, I): {np.mean(update_rewards[-print_freq:])}, ' + \\\n",
    "                  f'{np.mean(update_i_rewards[-print_freq:])}')\n",
    "#             print(f'I: {losses[0]}, F: {losses[1]}, P: {losses[2]}')\n",
    "#             print()\n",
    "    else:\n",
    "        network.train(dat, train_type=1) # Train the network with PPO\n",
    "\n",
    "        if i != 0 and i % print_freq == 0:\n",
    "            print(f'Update #{i}, Avg Reward (E): {np.mean(update_rewards[-print_freq:])}')\n",
    "        \n",
    "    if render and i != 0 and i % (print_freq * 5) == 0:\n",
    "        ec.render_episodes(network, 1, max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec.render_episodes(network, 5, max_steps) # Render an episode to see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
