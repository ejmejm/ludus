{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Breakout Example\n",
    "\n",
    "### Atari Breakout\n",
    "\n",
    "Please do note that this example may take a long time to train.\n",
    "\n",
    "With the default 4 threads runnning on an 8-core CPU with a GTX 1080 Ti, it will take several hours to train to a decent level of play.\n",
    "\n",
    "Running on a platform with more GPU power and a larger cluster of CPUs could siginificantly reduce training time.\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1705.05363.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "from ludus.policies import BaseTrainer\n",
    "from ludus.env import EnvController\n",
    "from ludus.utils import preprocess_atari, reshape_train_var\n",
    "from ludus.memory import MTMemoryBuffer\n",
    "import gym\n",
    "import multiprocessing as mp\n",
    "# Super Mario stuff\n",
    "from nes_py.wrappers import BinarySpaceToDiscreteSpaceEnv\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import COMPLEX_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "    env = BinarySpaceToDiscreteSpaceEnv(env, COMPLEX_MOVEMENT)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_obs(obs):\n",
    "    obs = cv2.resize(obs, obs_shape, interpolation=cv2.INTER_LINEAR)\n",
    "    obs = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
    "    return obs / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(make_env, max_steps=1000, act_repeat=6):\n",
    "    env = make_env()\n",
    "    obs = env.reset()\n",
    "    obs = filter_obs(obs)\n",
    "    \n",
    "    ep_reward = 0\n",
    "    for step in range(max_steps):\n",
    "        act = np.random.randint(0, 7)\n",
    "        \n",
    "        step_reward = 0\n",
    "        for i in range(act_repeat):\n",
    "            obs_p, r, d, _ = env.step(act)\n",
    "            step_reward += r\n",
    "            if d:\n",
    "                break\n",
    "        ep_reward += step_reward\n",
    "        \n",
    "        train_data.append([obs_buffer.copy(), act, step_reward])\n",
    "\n",
    "        obs_p = filter_obs(obs_p)\n",
    "        obs_buffer[:,:,:-1] = obs_buffer[:,:,1:]\n",
    "        obs_buffer[:,:,-1] = obs_p\n",
    "\n",
    "        train_data[-1].append(obs_buffer.copy())\n",
    "\n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(0.02)\n",
    "\n",
    "        if len(train_data) >= steps_per_epoch:\n",
    "            np.random.shuffle(train_data)\n",
    "            train_obs = np.array([x[0] for x in train_data])\n",
    "            train_acts = np.array([x[1] for x in train_data])\n",
    "            train_rewards = np.array([x[2] for x in train_data])\n",
    "            train_obs_ps = np.array([x[3] for x in train_data])\n",
    "\n",
    "            nri, li, lf, lp, _, _, _ = sess.run([ri] + icm_losses + icm_objective,\n",
    "                                    feed_dict={\n",
    "                                        state_ph: train_obs,\n",
    "                                        act_ph: train_acts,\n",
    "                                        state_p_ph: train_obs_ps\n",
    "                                    })\n",
    "            ris += nri\n",
    "            lis += li\n",
    "            lfs += lf\n",
    "            lps += lp\n",
    "            train_iters += 1\n",
    "            \n",
    "            train_data = []\n",
    "\n",
    "        if d:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1000000\n",
    "steps_per_epoch = 2048\n",
    "print_freq = 8\n",
    "act_skip = 6\n",
    "max_steps = int(4096 / act_skip)\n",
    "render = False\n",
    "\n",
    "all_rewards = []\n",
    "train_iters = 0\n",
    "train_data = [] # Formatted as [obs_buffer_t, act_t, reward_t, obs_buffer_t+1]\n",
    "best_runs = []\n",
    "for episode in range(n_episodes):\n",
    "    obs = env.reset()\n",
    "    obs = filter_obs(obs)\n",
    "    # obs_buffer = np.rollaxis(np.array([obs] * obs_buffer_size), 0, 3)\n",
    "    ep_reward = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        act = np.random.randint(0, 7)\n",
    "        \n",
    "        step_reward = 0\n",
    "        for i in range(act_skip):\n",
    "            obs_p, r, d, _ = env.step(act)\n",
    "            step_reward += r\n",
    "            if d:\n",
    "                break\n",
    "        ep_reward += step_reward\n",
    "        \n",
    "        train_data.append([obs_buffer.copy(), act, step_reward])\n",
    "\n",
    "        obs_p = filter_obs(obs_p)\n",
    "        obs_buffer[:,:,:-1] = obs_buffer[:,:,1:]\n",
    "        obs_buffer[:,:,-1] = obs_p\n",
    "\n",
    "        train_data[-1].append(obs_buffer.copy())\n",
    "\n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(0.02)\n",
    "\n",
    "        if len(train_data) >= steps_per_epoch:\n",
    "            np.random.shuffle(train_data)\n",
    "            train_obs = np.array([x[0] for x in train_data])\n",
    "            train_acts = np.array([x[1] for x in train_data])\n",
    "            train_rewards = np.array([x[2] for x in train_data])\n",
    "            train_obs_ps = np.array([x[3] for x in train_data])\n",
    "\n",
    "            nri, li, lf, lp, _, _, _ = sess.run([ri] + icm_losses + icm_objective,\n",
    "                                    feed_dict={\n",
    "                                        state_ph: train_obs,\n",
    "                                        act_ph: train_acts,\n",
    "                                        state_p_ph: train_obs_ps\n",
    "                                    })\n",
    "            ris += nri\n",
    "            lis += li\n",
    "            lfs += lf\n",
    "            lps += lp\n",
    "            train_iters += 1\n",
    "            \n",
    "            train_data = []\n",
    "\n",
    "        if d:\n",
    "            break\n",
    "            \n",
    "    if ep_reward >= 2300:\n",
    "        best_runs.append(copy.deepcopy(train_data[-step-1:]))\n",
    "        print(f'Run with {ep_reward} reward')\n",
    "\n",
    "    all_rewards.append(ep_reward)\n",
    "\n",
    "    if (episode + 1) % print_freq == 0:\n",
    "        print(f'R_e: {np.mean(all_rewards[-print_freq:])}, R_i: {ris/train_iters}')\n",
    "        print(f'L_i: {lis/train_iters}, L_f: {lfs/train_iters}, L_p: {lps/train_iters}')\n",
    "        print()\n",
    "        \n",
    "        ris, lis, lfs, lps = 0, 0, 0, 0\n",
    "        train_iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target():\n",
    "    for i in range(10000000):\n",
    "        a = 5 * 5 / (2^10) + 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9958672008942813"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(\"\"\"\n",
    "def target():\n",
    "    for i in range(10000000):\n",
    "        a = 5 * 5 / (2^10) + 34\n",
    "\n",
    "for i in range(8): \n",
    "    target()\"\"\", number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5992502459557727"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(\"\"\"\n",
    "from multiprocessing import Process\n",
    "def target():\n",
    "    for i in range(int(10000000/3)):\n",
    "        a = 5 * 5 / (2^10) + 34\n",
    "\n",
    "ps = []\n",
    "for i in range(24):\n",
    "    ps.append(Process(target=target))\n",
    "    ps[-1].start()\n",
    "\n",
    "for i in range(len(ps)):\n",
    "    ps[i].join()\n",
    "\"\"\", number=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
